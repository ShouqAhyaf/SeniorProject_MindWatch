{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee9af24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fused dataset...\n",
      "Data shape: (1622677, 86)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0    1312916\n",
      "1     289844\n",
      "2      19917\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label proportions (%):\n",
      "label\n",
      "0    80.910495\n",
      "1    17.862088\n",
      "2     1.227416\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Meta columns:\n",
      "['subject', 'run', 'window_idx', 'label', 'run_base', 'ecg_start_time_sec', 't_start', 't_end', 'win_idx', 'Unnamed: 0', 'timestamp_center']\n",
      "\n",
      "Number of feature columns: 75\n",
      "Example feature columns: ['ch1_Delta Bandpower', 'ch1_Theta Bandpower', 'ch1_Alpha Bandpower', 'ch1_Beta Bandpower', 'ch1_Gamma Bandpower', 'ch1_Relative Delta Bandpower', 'ch1_Relative Theta Bandpower', 'ch1_Relative Alpha Bandpower', 'ch1_Relative Beta Bandpower', 'ch1_Relative Gamma Bandpower']\n",
      "Unique labels: [0 1 2]\n",
      "\n",
      "Total hyperparameter combinations in inner loop: 18\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 1/10\n",
      "################################################################################\n",
      "Train+Val subjects: 101, Test subjects: 12\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6128\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6096\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6095\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6055\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6082\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6069\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6104\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6077\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6068\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6038\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6060\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6051\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6081\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6055\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6061\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6027\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6049\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6037\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.6128\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_01.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 1 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.7857\t\t0.7282\t\t0.7558\t\t118025\n",
      "1\t0.1795\t\t0.1945\t\t0.1867\t\t29174\n",
      "2\t0.0706\t\t0.3529\t\t0.1176\t\t1553\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.6196\n",
      "Balanced Accuracy : 0.4252\n",
      "Micro-F1          : 0.6196\n",
      "Macro-F1          : 0.3534\n",
      "Weighted-F1       : 0.6375\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[85941 25734  6350]\n",
      " [22632  5673   869]\n",
      " [  812   193   548]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=85941, FP=23444, FN=32084, TN=7283\n",
      "Label 1: TP=5673, FP=25927, FN=23501, TN=93651\n",
      "Label 2: TP=548, FP=7219, FN=1005, TN=139980\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 2/10\n",
      "################################################################################\n",
      "Train+Val subjects: 101, Test subjects: 12\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6031\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6021\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6031\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6021\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6045\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6036\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6008\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6010\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6031\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6014\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6036\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6022\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6006\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6010\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6017\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6001\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6022\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6012\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.6045\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_02.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 2 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.8166\t\t0.7332\t\t0.7726\t\t71955\n",
      "1\t0.1891\t\t0.2585\t\t0.2184\t\t15414\n",
      "2\t0.1972\t\t0.4435\t\t0.2730\t\t1353\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.6463\n",
      "Balanced Accuracy : 0.4784\n",
      "Micro-F1          : 0.6463\n",
      "Macro-F1          : 0.4214\n",
      "Weighted-F1       : 0.6687\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[52759 16969  2227]\n",
      " [11215  3984   215]\n",
      " [  638   115   600]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=52759, FP=11853, FN=19196, TN=4914\n",
      "Label 1: TP=3984, FP=17084, FN=11430, TN=56224\n",
      "Label 2: TP=600, FP=2442, FN=753, TN=84927\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 3/10\n",
      "################################################################################\n",
      "Train+Val subjects: 101, Test subjects: 12\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6161\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6158\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6160\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6114\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6127\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6110\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6160\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6137\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6133\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6075\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6103\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6091\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6150\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6123\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6107\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6056\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6091\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6074\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.6161\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_03.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 3 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.7852\t\t0.5867\t\t0.6716\t\t134322\n",
      "1\t0.2020\t\t0.3522\t\t0.2567\t\t34765\n",
      "2\t0.0960\t\t0.4361\t\t0.1573\t\t2286\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.5371\n",
      "Balanced Accuracy : 0.4583\n",
      "Micro-F1          : 0.5371\n",
      "Macro-F1          : 0.3619\n",
      "Weighted-F1       : 0.5805\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[78804 47968  7550]\n",
      " [20682 12243  1840]\n",
      " [  880   409   997]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=78804, FP=21562, FN=55518, TN=15489\n",
      "Label 1: TP=12243, FP=48377, FN=22522, TN=88231\n",
      "Label 2: TP=997, FP=9390, FN=1289, TN=159697\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 4/10\n",
      "################################################################################\n",
      "Train+Val subjects: 102, Test subjects: 11\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6176\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6152\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6150\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6128\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6125\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6133\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6150\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6125\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6131\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6111\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6112\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6111\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6125\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6106\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6116\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6096\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6102\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6090\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.6176\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_04.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 4 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.8044\t\t0.6775\t\t0.7355\t\t104119\n",
      "1\t0.1113\t\t0.1423\t\t0.1249\t\t21317\n",
      "2\t0.0384\t\t0.3701\t\t0.0696\t\t1216\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.5845\n",
      "Balanced Accuracy : 0.3966\n",
      "Micro-F1          : 0.5845\n",
      "Macro-F1          : 0.3100\n",
      "Weighted-F1       : 0.6263\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[70539 24050  9530]\n",
      " [16557  3033  1727]\n",
      " [  600   166   450]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=70539, FP=17157, FN=33580, TN=5376\n",
      "Label 1: TP=3033, FP=24216, FN=18284, TN=81119\n",
      "Label 2: TP=450, FP=11257, FN=766, TN=114179\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 5/10\n",
      "################################################################################\n",
      "Train+Val subjects: 102, Test subjects: 11\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6132\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6134\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6128\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6107\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6099\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6082\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6148\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6120\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6117\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6076\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6089\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6080\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6132\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6095\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6104\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6067\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6083\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6065\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.6148\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_05.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 5 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.7732\t\t0.6353\t\t0.6975\t\t210343\n",
      "1\t0.2215\t\t0.3232\t\t0.2629\t\t58623\n",
      "2\t0.1068\t\t0.3993\t\t0.1685\t\t3874\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.5649\n",
      "Balanced Accuracy : 0.4526\n",
      "Micro-F1          : 0.5649\n",
      "Macro-F1          : 0.3763\n",
      "Weighted-F1       : 0.5966\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[133622  66081  10640]\n",
      " [ 37374  18947   2302]\n",
      " [  1814    513   1547]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=133622, FP=39188, FN=76721, TN=23309\n",
      "Label 1: TP=18947, FP=66594, FN=39676, TN=147623\n",
      "Label 2: TP=1547, FP=12942, FN=2327, TN=256024\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 6/10\n",
      "################################################################################\n",
      "Train+Val subjects: 102, Test subjects: 11\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6121\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6106\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6106\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6084\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6090\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6077\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6113\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6101\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6104\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6068\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6086\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6076\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6110\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6097\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6094\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6069\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6079\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6072\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.6121\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_06.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 6 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.8007\t\t0.7107\t\t0.7531\t\t124554\n",
      "1\t0.1858\t\t0.2052\t\t0.1950\t\t28842\n",
      "2\t0.0669\t\t0.4479\t\t0.1164\t\t1929\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.6136\n",
      "Balanced Accuracy : 0.4546\n",
      "Micro-F1          : 0.6136\n",
      "Macro-F1          : 0.3548\n",
      "Weighted-F1       : 0.6415\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[88525 25908 10121]\n",
      " [20998  5918  1926]\n",
      " [ 1031    34   864]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=88525, FP=22029, FN=36029, TN=8742\n",
      "Label 1: TP=5918, FP=25942, FN=22924, TN=100541\n",
      "Label 2: TP=864, FP=12047, FN=1065, TN=141349\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 7/10\n",
      "################################################################################\n",
      "Train+Val subjects: 102, Test subjects: 11\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6189\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6128\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6125\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6097\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6100\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6066\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6148\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6094\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6098\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6062\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6073\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6052\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6120\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6079\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6082\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6050\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6061\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6049\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.6189\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_07.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 7 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.7849\t\t0.6304\t\t0.6992\t\t84867\n",
      "1\t0.1819\t\t0.2625\t\t0.2149\t\t20684\n",
      "2\t0.0340\t\t0.1824\t\t0.0574\t\t1727\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.5523\n",
      "Balanced Accuracy : 0.3584\n",
      "Micro-F1          : 0.5523\n",
      "Macro-F1          : 0.3238\n",
      "Weighted-F1       : 0.5955\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[53502 24191  7174]\n",
      " [13486  5430  1768]\n",
      " [ 1177   235   315]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=53502, FP=14663, FN=31365, TN=7748\n",
      "Label 1: TP=5430, FP=24426, FN=15254, TN=62168\n",
      "Label 2: TP=315, FP=8942, FN=1412, TN=96609\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 8/10\n",
      "################################################################################\n",
      "Train+Val subjects: 102, Test subjects: 11\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6086\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6056\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6047\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6043\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6032\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6012\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6054\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6037\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6021\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6038\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6014\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6016\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6044\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6035\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6015\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6031\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6015\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6018\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.6086\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_08.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 8 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.8829\t\t0.5348\t\t0.6661\t\t124514\n",
      "1\t0.1651\t\t0.4300\t\t0.2385\t\t20462\n",
      "2\t0.0425\t\t0.6149\t\t0.0794\t\t1205\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.5208\n",
      "Balanced Accuracy : 0.5266\n",
      "Micro-F1          : 0.5208\n",
      "Macro-F1          : 0.3280\n",
      "Weighted-F1       : 0.6014\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[66588 44321 13605]\n",
      " [ 8554  8799  3109]\n",
      " [  274   190   741]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=66588, FP=8828, FN=57926, TN=12839\n",
      "Label 1: TP=8799, FP=44511, FN=11663, TN=81208\n",
      "Label 2: TP=741, FP=16714, FN=464, TN=128262\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 9/10\n",
      "################################################################################\n",
      "Train+Val subjects: 102, Test subjects: 11\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6076\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6048\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6052\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6014\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6034\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6026\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6043\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6007\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6033\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5991\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6017\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5997\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6029\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5988\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6018\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5988\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.6011\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5989\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.6076\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_09.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 9 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.8548\t\t0.6306\t\t0.7258\t\t193928\n",
      "1\t0.1466\t\t0.3348\t\t0.2039\t\t31032\n",
      "2\t0.0708\t\t0.3196\t\t0.1159\t\t3138\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.5861\n",
      "Balanced Accuracy : 0.4283\n",
      "Micro-F1          : 0.5861\n",
      "Macro-F1          : 0.3485\n",
      "Weighted-F1       : 0.6464\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[122287  60069  11572]\n",
      " [ 19044  10389   1599]\n",
      " [  1731    404   1003]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=122287, FP=20775, FN=71641, TN=13395\n",
      "Label 1: TP=10389, FP=60473, FN=20643, TN=136593\n",
      "Label 2: TP=1003, FP=13171, FN=2135, TN=211789\n",
      "\n",
      "################################################################################\n",
      "OUTER Fold 10/10\n",
      "################################################################################\n",
      "Train+Val subjects: 102, Test subjects: 11\n",
      "\n",
      "------------------------------------------------------\n",
      "Inner loop ROC AUC hyperparameter tuning (XGBoost)\n",
      "------------------------------------------------------\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 1/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5990\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 2/18: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5967\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 3/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5943\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 4/18: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5932\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 5/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5924\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 6/18: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5923\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 7/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5954\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 8/18: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5923\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 9/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5912\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 10/18: {'n_estimators': 600, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5916\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 11/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5910\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 12/18: {'n_estimators': 600, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5927\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 13/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5934\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 14/18: {'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5906\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 15/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5908\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 16/18: {'n_estimators': 1000, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5910\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 17/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5907\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Combo 18/18: {'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8} --> mean macro ROC AUC = 0.5925\n",
      "\n",
      "Best inner hyperparameters based on ROC AUC:\n",
      "{'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best inner mean macro ROC AUC: 0.5990\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "Saved outer fold model to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_nested_outer_10.pkl\n",
      "\n",
      "======================================================================\n",
      "OUTER Fold 10 Test Metrics\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.8398\t\t0.7237\t\t0.7774\t\t146289\n",
      "1\t0.2153\t\t0.3198\t\t0.2573\t\t29531\n",
      "2\t0.0953\t\t0.4389\t\t0.1566\t\t1636\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.6538\n",
      "Balanced Accuracy : 0.4941\n",
      "Micro-F1          : 0.6538\n",
      "Macro-F1          : 0.3971\n",
      "Weighted-F1       : 0.6852\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[105863  34321   6105]\n",
      " [ 19378   9445    708]\n",
      " [   810    108    718]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=105863, FP=20188, FN=40426, TN=10979\n",
      "Label 1: TP=9445, FP=34429, FN=20086, TN=113496\n",
      "Label 2: TP=718, FP=6813, FN=918, TN=169007\n",
      "\n",
      "======================================================================\n",
      "GLOBAL Test Metrics Across All OUTER Folds (XGBoost)\n",
      "======================================================================\n",
      "\n",
      "Per-class metrics:\n",
      "label\tprecision\trecall\t\tf1-score\tsupport\n",
      "0\t0.8113\t\t0.6538\t\t0.7241\t\t1312916\n",
      "1\t0.1840\t\t0.2893\t\t0.2249\t\t289844\n",
      "2\t0.0716\t\t0.3908\t\t0.1210\t\t19917\n",
      "\n",
      "Global metrics:\n",
      "Accuracy          : 0.5855\n",
      "Balanced Accuracy : 0.4446\n",
      "Micro-F1          : 0.5855\n",
      "Macro-F1          : 0.3567\n",
      "Weighted-F1       : 0.6275\n",
      "\n",
      "Confusion matrix (rows = true, cols = predicted):\n",
      "[[858430 369612  84874]\n",
      " [189920  83861  16063]\n",
      " [  9767   2367   7783]]\n",
      "\n",
      "Per-class confusion details (TP, FP, FN, TN):\n",
      "Label 0: TP=858430, FP=199687, FN=454486, TN=110074\n",
      "Label 1: TP=83861, FP=371979, FN=205983, TN=960854\n",
      "Label 2: TP=7783, FP=100937, FN=12134, TN=1501823\n",
      "\n",
      "Nested 10×10 N-LNSO evaluation with XGBoost completed.\n",
      "All outer-fold models are saved and ready for external testing.\n",
      "\n",
      "======================================================================\n",
      "Summary of inner-loop ROC AUC used to select best hyperparameters (XGBoost)\n",
      "======================================================================\n",
      "OUTER Fold 01: best inner mean macro ROC AUC = 0.6128\n",
      "  Selected params: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "OUTER Fold 02: best inner mean macro ROC AUC = 0.6045\n",
      "  Selected params: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "OUTER Fold 03: best inner mean macro ROC AUC = 0.6161\n",
      "  Selected params: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "OUTER Fold 04: best inner mean macro ROC AUC = 0.6176\n",
      "  Selected params: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "OUTER Fold 05: best inner mean macro ROC AUC = 0.6148\n",
      "  Selected params: {'n_estimators': 600, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "OUTER Fold 06: best inner mean macro ROC AUC = 0.6121\n",
      "  Selected params: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "OUTER Fold 07: best inner mean macro ROC AUC = 0.6189\n",
      "  Selected params: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "OUTER Fold 08: best inner mean macro ROC AUC = 0.6086\n",
      "  Selected params: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "OUTER Fold 09: best inner mean macro ROC AUC = 0.6076\n",
      "  Selected params: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "OUTER Fold 10: best inner mean macro ROC AUC = 0.5990\n",
      "  Selected params: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "======================================================================\n",
      "Inner-loop ROC AUC summary saved to: C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_inner_auc_summary.csv\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Selected FINAL deployment hyperparameters (based on outer folds, XGBoost):\n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Selected combo frequency across outer folds: 8\n",
      "======================================================================\n",
      "[XGBoost] Using GPU (hist + device='cuda') ✅\n",
      "\n",
      "Final deployment XGBoost model trained on all subjects and saved to:\n",
      "C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\\xgb_final_deployment.pkl\n",
      "Use this model for real-time or external testing on new patients.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.utils import shuffle\n",
    "import joblib\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ============================================================\n",
    "# 1) Paths and basic settings (edit these to match your system)\n",
    "# ============================================================\n",
    "\n",
    "# Path to the fused dataset (CSV)\n",
    "DATA_PATH = Path(r\"C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\Data\\FUSED_ALL_FINAL_FROM_DATA_ALL.csv\")\n",
    "\n",
    "# Directory where all XGBoost models and CSV summaries will be saved\n",
    "MODELS_DIR = Path(r\"C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\")\n",
    "\n",
    "# Column names for subject ID and label\n",
    "SUBJECT_COL = \"subject\"\n",
    "LABEL_COL   = \"label\"\n",
    "\n",
    "# Global random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Number of outer and inner folds for nested N-LNSO\n",
    "N_OUTER_FOLDS = 10\n",
    "N_INNER_FOLDS = 10\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Helper functions\n",
    "# ============================================================\n",
    "\n",
    "def make_subject_folds(subject_ids, n_folds=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Create subject-wise folds:\n",
    "    - Take unique subject IDs\n",
    "    - Shuffle them\n",
    "    - Split them into n_folds groups\n",
    "    Each fold contains a set of subjects (not windows).\n",
    "    \"\"\"\n",
    "    unique_subjects = np.array(sorted(np.unique(subject_ids)))\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    rng.shuffle(unique_subjects)\n",
    "    folds = np.array_split(unique_subjects, n_folds)\n",
    "    return folds\n",
    "\n",
    "\n",
    "def undersample_multiclass(X, y, max_ratio=3.0, random_state=42):\n",
    "    \"\"\"\n",
    "    Random undersampling for imbalanced multi-class data.\n",
    "    For each class c:\n",
    "        keep at most (max_ratio * min_class_count) samples.\n",
    "    This avoids extreme imbalance across classes.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    max_per_class = {c: int(min_count * max_ratio) for c in classes}\n",
    "\n",
    "    indices_to_keep = []\n",
    "\n",
    "    for c in classes:\n",
    "        class_indices = np.where(y == c)[0]\n",
    "        n_keep = min(len(class_indices), max_per_class[c])\n",
    "        chosen = rng.choice(class_indices, size=n_keep, replace=False)\n",
    "        indices_to_keep.append(chosen)\n",
    "\n",
    "    indices_to_keep = np.concatenate(indices_to_keep)\n",
    "    indices_to_keep = shuffle(indices_to_keep, random_state=random_state)\n",
    "\n",
    "    return X[indices_to_keep], y[indices_to_keep]\n",
    "\n",
    "\n",
    "def get_xgb_model(params, n_classes, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Build an XGBClassifier for multi-class classification\n",
    "    using the provided hyperparameters.\n",
    "\n",
    "    XGBoost >= 2.0:\n",
    "      - GPU:  tree_method=\"hist\", device=\"cuda\"\n",
    "      - CPU:  tree_method=\"hist\"\n",
    "    \"\"\"\n",
    "    base_kwargs = dict(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        subsample=params[\"subsample\"],\n",
    "        colsample_bytree=params[\"colsample_bytree\"],\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=n_classes,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    if use_gpu:\n",
    "        try:\n",
    "            # 🔥 GPU mode (الطريقة الجديدة)\n",
    "            model = XGBClassifier(\n",
    "                tree_method=\"hist\",\n",
    "                device=\"cuda\",\n",
    "                **base_kwargs,\n",
    "            )\n",
    "            print(\"[XGBoost] Using GPU (hist + device='cuda') ✅\")\n",
    "        except Exception as e:\n",
    "            print(\"[XGBoost] GPU not available, falling back to CPU ❌\")\n",
    "            print(\"Reason:\", e)\n",
    "            model = XGBClassifier(\n",
    "                tree_method=\"hist\",\n",
    "                **base_kwargs,\n",
    "            )\n",
    "    else:\n",
    "        # 🧠 CPU فقط\n",
    "        model = XGBClassifier(\n",
    "            tree_method=\"hist\",\n",
    "            **base_kwargs,\n",
    "        )\n",
    "        print(\"[XGBoost] Using CPU only (hist) 🧠\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def xgb_fit_predict_proba(X_train, y_train, X_val, params, n_classes):\n",
    "    \"\"\"\n",
    "    Train XGBoost on (X_train, y_train) and predict class probabilities on X_val.\n",
    "    Returns:\n",
    "        model       - trained XGBClassifier\n",
    "        y_val_proba - numpy array of shape (n_samples_val, n_classes)\n",
    "    \"\"\"\n",
    "    model = get_xgb_model(params, n_classes, use_gpu=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_proba = model.predict_proba(X_val)\n",
    "    return model, y_val_proba\n",
    "\n",
    "\n",
    "def xgb_fit_predict(X_train, y_train, X_test, params, n_classes):\n",
    "    \"\"\"\n",
    "    Train XGBoost on (X_train, y_train) and predict class labels on X_test.\n",
    "    Returns:\n",
    "        model       - trained XGBClassifier\n",
    "        y_test_pred - numpy array of predicted class labels\n",
    "    \"\"\"\n",
    "    model = get_xgb_model(params, n_classes, use_gpu=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    return model, y_test_pred\n",
    "\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred, label_set=None):\n",
    "    \"\"\"\n",
    "    Compute per-class and global evaluation metrics:\n",
    "    - per-class precision, recall, f1, support\n",
    "    - accuracy, balanced accuracy, micro-F1, macro-F1, weighted-F1\n",
    "    - confusion matrix\n",
    "    \"\"\"\n",
    "    if label_set is None:\n",
    "        label_set = np.unique(y_true)\n",
    "\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=label_set, zero_division=0\n",
    "    )\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    micro_f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=label_set)\n",
    "\n",
    "    metrics = {\n",
    "        \"labels\": label_set,\n",
    "        \"precision_per_class\": prec,\n",
    "        \"recall_per_class\": rec,\n",
    "        \"f1_per_class\": f1,\n",
    "        \"support_per_class\": support,\n",
    "        \"accuracy\": acc,\n",
    "        \"balanced_accuracy\": bal_acc,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_metrics(metrics, header=\"\"):\n",
    "    \"\"\"\n",
    "    Pretty-print per-class and global metrics,\n",
    "    and show TP/FP/FN/TN per label from the confusion matrix.\n",
    "    \"\"\"\n",
    "    labels = metrics[\"labels\"]\n",
    "    prec = metrics[\"precision_per_class\"]\n",
    "    rec = metrics[\"recall_per_class\"]\n",
    "    f1 = metrics[\"f1_per_class\"]\n",
    "    support = metrics[\"support_per_class\"]\n",
    "    cm = metrics[\"confusion_matrix\"]\n",
    "\n",
    "    if header:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(header)\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    print(\"label\\tprecision\\trecall\\t\\tf1-score\\tsupport\")\n",
    "    for i, c in enumerate(labels):\n",
    "        print(f\"{c}\\t{prec[i]:.4f}\\t\\t{rec[i]:.4f}\\t\\t{f1[i]:.4f}\\t\\t{support[i]}\")\n",
    "\n",
    "    print(\"\\nGlobal metrics:\")\n",
    "    print(f\"Accuracy          : {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Balanced Accuracy : {metrics['balanced_accuracy']:.4f}\")\n",
    "    print(f\"Micro-F1          : {metrics['micro_f1']:.4f}\")\n",
    "    print(f\"Macro-F1          : {metrics['macro_f1']:.4f}\")\n",
    "    print(f\"Weighted-F1       : {metrics['weighted_f1']:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion matrix (rows = true, cols = predicted):\")\n",
    "    print(cm)\n",
    "\n",
    "    total = cm.sum()\n",
    "    print(\"\\nPer-class confusion details (TP, FP, FN, TN):\")\n",
    "    for idx, c in enumerate(labels):\n",
    "        TP = cm[idx, idx]\n",
    "        FP = cm[:, idx].sum() - TP\n",
    "        FN = cm[idx, :].sum() - TP\n",
    "        TN = total - (TP + FP + FN)\n",
    "        print(f\"Label {c}: TP={TP}, FP={FP}, FN={FN}, TN={TN}\")\n",
    "\n",
    "\n",
    "def compute_inner_roc_auc_for_params(\n",
    "    X, y, subjects, label_set, param_grid, n_inner_folds=10, max_ratio=3.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Inner loop for nested N-LNSO:\n",
    "    - Split train+val subjects into n_inner_folds (subject-wise).\n",
    "    - For each hyperparameter combination:\n",
    "        - Train on inner-train subjects (with undersampling)\n",
    "        - Validate on inner-val subjects\n",
    "        - Compute macro ROC AUC (multi-class 'ovr')\n",
    "    - Return:\n",
    "        best_params, best_auc\n",
    "    \"\"\"\n",
    "    inner_folds = make_subject_folds(\n",
    "        subjects, n_folds=n_inner_folds, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    combo_scores = []\n",
    "    n_classes = len(label_set)\n",
    "\n",
    "    print(\"\\n------------------------------------------------------\")\n",
    "    print(\"Inner loop ROC AUC hyperparameter tuning (XGBoost)\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "\n",
    "    for combo_idx, params in enumerate(param_grid):\n",
    "        fold_aucs = []\n",
    "\n",
    "        for inner_idx, inner_val_subjects in enumerate(inner_folds):\n",
    "            # Subject-wise split for inner validation\n",
    "            is_inner_val = np.isin(subjects, inner_val_subjects)\n",
    "            is_inner_train = ~is_inner_val\n",
    "\n",
    "            X_inner_train = X[is_inner_train]\n",
    "            y_inner_train = y[is_inner_train]\n",
    "            X_inner_val   = X[is_inner_val]\n",
    "            y_inner_val   = y[is_inner_val]\n",
    "\n",
    "            # Undersampling on inner training set (only)\n",
    "            X_inner_train_bal, y_inner_train_bal = undersample_multiclass(\n",
    "                X_inner_train,\n",
    "                y_inner_train,\n",
    "                max_ratio=max_ratio,\n",
    "                random_state=RANDOM_STATE + inner_idx\n",
    "            )\n",
    "\n",
    "            # Train XGBoost and get probabilities on validation set\n",
    "            _, y_inner_val_proba = xgb_fit_predict_proba(\n",
    "                X_inner_train_bal, y_inner_train_bal,\n",
    "                X_inner_val,\n",
    "                params,\n",
    "                n_classes=n_classes\n",
    "            )\n",
    "\n",
    "            # Compute macro ROC AUC if possible for this fold\n",
    "            try:\n",
    "                auc = roc_auc_score(\n",
    "                    y_inner_val,\n",
    "                    y_inner_val_proba,\n",
    "                    labels=label_set,\n",
    "                    multi_class=\"ovr\",\n",
    "                    average=\"macro\"\n",
    "                )\n",
    "                fold_aucs.append(auc)\n",
    "            except ValueError:\n",
    "                # If the validation fold has only one class, ROC AUC is undefined\n",
    "                # => skip this fold for AUC calculation\n",
    "                continue\n",
    "\n",
    "        # Mean ROC AUC across inner folds for this hyperparameter combination\n",
    "        if len(fold_aucs) == 0:\n",
    "            mean_auc = np.nan\n",
    "        else:\n",
    "            mean_auc = float(np.mean(fold_aucs))\n",
    "\n",
    "        combo_scores.append((params, mean_auc))\n",
    "        print(f\"Combo {combo_idx + 1}/{len(param_grid)}: \"\n",
    "              f\"{params} --> mean macro ROC AUC = {mean_auc:.4f}\")\n",
    "\n",
    "    # Filter out combinations where all inner-fold AUCs were NaN\n",
    "    combo_scores = [c for c in combo_scores if not np.isnan(c[1])]\n",
    "    if len(combo_scores) == 0:\n",
    "        raise RuntimeError(\"All inner ROC AUC scores are NaN. Check your data splits or labels.\")\n",
    "\n",
    "    # Select the hyperparameters with the highest mean ROC AUC\n",
    "    best_params, best_auc = max(combo_scores, key=lambda t: t[1])\n",
    "\n",
    "    print(\"\\nBest inner hyperparameters based on ROC AUC:\")\n",
    "    print(best_params)\n",
    "    print(f\"Best inner mean macro ROC AUC: {best_auc:.4f}\")\n",
    "\n",
    "    return best_params, best_auc\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Load data and define feature/meta columns\n",
    "# ============================================================\n",
    "\n",
    "print(\"Loading fused dataset...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "if SUBJECT_COL not in df.columns or LABEL_COL not in df.columns:\n",
    "    raise ValueError(\"Check SUBJECT_COL and LABEL_COL names. They are not found in the dataframe.\")\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df[LABEL_COL].value_counts())\n",
    "print(\"\\nLabel proportions (%):\")\n",
    "print(df[LABEL_COL].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Meta columns (not used as features)\n",
    "meta_cols = [\n",
    "    \"subject\", \"run\", \"window_idx\", \"label\", \"run_base\",\n",
    "    \"ecg_start_time_sec\", \"t_start\", \"t_end\",\n",
    "    \"win_idx\", \"Unnamed: 0\", \"timestamp_center\"\n",
    "]\n",
    "# Keep only those that actually exist in the dataframe\n",
    "meta_cols = [c for c in meta_cols if c in df.columns]\n",
    "\n",
    "print(\"\\nMeta columns:\")\n",
    "print(meta_cols)\n",
    "\n",
    "# Select only numeric columns as candidate features\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "# Final feature columns = numeric columns minus meta columns\n",
    "feature_cols = [c for c in numeric_cols if c not in meta_cols]\n",
    "\n",
    "print(f\"\\nNumber of feature columns: {len(feature_cols)}\")\n",
    "print(\"Example feature columns:\", feature_cols[:10])\n",
    "\n",
    "# Build X, y, and subject arrays\n",
    "X_all = df[feature_cols].values\n",
    "y_all = df[LABEL_COL].values\n",
    "subjects_all = df[SUBJECT_COL].values\n",
    "\n",
    "label_set = np.unique(y_all)\n",
    "print(f\"Unique labels: {label_set}\")\n",
    "\n",
    "n_classes = len(label_set)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Nested 10x10 N-LNSO with ROC AUC inner tuning (XGBoost)\n",
    "# ============================================================\n",
    "\n",
    "# Hyperparameter grid for inner ROC AUC tuning.\n",
    "param_grid = []\n",
    "\n",
    "n_estimators_list      = [300, 600, 1000]\n",
    "max_depth_list         = [4, 6, 8]\n",
    "learning_rate_list     = [0.05, 0.1]\n",
    "subsample_list         = [0.8]\n",
    "colsample_bytree_list  = [0.8]\n",
    "\n",
    "for ne in n_estimators_list:\n",
    "    for md in max_depth_list:\n",
    "        for lr in learning_rate_list:\n",
    "            for ss in subsample_list:\n",
    "                for cs in colsample_bytree_list:\n",
    "                    param_grid.append({\n",
    "                        \"n_estimators\": ne,\n",
    "                        \"max_depth\": md,\n",
    "                        \"learning_rate\": lr,\n",
    "                        \"subsample\": ss,\n",
    "                        \"colsample_bytree\": cs,\n",
    "                    })\n",
    "\n",
    "print(f\"\\nTotal hyperparameter combinations in inner loop: {len(param_grid)}\")\n",
    "\n",
    "# Outer folds (N-LNSO outer loop at subject level)\n",
    "outer_folds = make_subject_folds(\n",
    "    subjects_all,\n",
    "    n_folds=N_OUTER_FOLDS,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "all_test_y_true = []\n",
    "all_test_y_pred = []\n",
    "\n",
    "# Store best hyperparameters and macro-F1 from each outer fold\n",
    "outer_best_params_list = []\n",
    "outer_macro_f1_list = []\n",
    "outer_best_auc_list = []\n",
    "\n",
    "for outer_idx, outer_test_subjects in enumerate(outer_folds):\n",
    "    print(\"\\n\" + \"#\" * 80)\n",
    "    print(f\"OUTER Fold {outer_idx + 1}/{N_OUTER_FOLDS}\")\n",
    "    print(\"#\" * 80)\n",
    "\n",
    "    # Subject-wise split into Test vs Train+Val for this outer fold\n",
    "    is_test = np.isin(subjects_all, outer_test_subjects)\n",
    "    is_trainval = ~is_test\n",
    "\n",
    "    X_trainval = X_all[is_trainval]\n",
    "    y_trainval = y_all[is_trainval]\n",
    "    subjects_trainval = subjects_all[is_trainval]\n",
    "\n",
    "    X_test = X_all[is_test]\n",
    "    y_test = y_all[is_test]\n",
    "    subjects_test = subjects_all[is_test]\n",
    "\n",
    "    print(f\"Train+Val subjects: {len(np.unique(subjects_trainval))}, \"\n",
    "          f\"Test subjects: {len(np.unique(subjects_test))}\")\n",
    "\n",
    "    # ============================\n",
    "    # Inner loop: ROC AUC tuning\n",
    "    # ============================\n",
    "    best_inner_params, best_inner_auc = compute_inner_roc_auc_for_params(\n",
    "        X_trainval, y_trainval, subjects_trainval,\n",
    "        label_set=label_set,\n",
    "        param_grid=param_grid,\n",
    "        n_inner_folds=N_INNER_FOLDS,\n",
    "        max_ratio=3.0\n",
    "    )\n",
    "\n",
    "    outer_best_params_list.append(best_inner_params)\n",
    "    outer_best_auc_list.append(best_inner_auc)\n",
    "\n",
    "    # ============================\n",
    "    # Train final model on all Train+Val with undersampling\n",
    "    # ============================\n",
    "    X_trainval_bal, y_trainval_bal = undersample_multiclass(\n",
    "        X_trainval, y_trainval,\n",
    "        max_ratio=3.0,\n",
    "        random_state=RANDOM_STATE + outer_idx\n",
    "    )\n",
    "\n",
    "    final_model, y_test_pred = xgb_fit_predict(\n",
    "        X_trainval_bal, y_trainval_bal,\n",
    "        X_test,\n",
    "        best_inner_params,\n",
    "        n_classes=n_classes\n",
    "    )\n",
    "\n",
    "    # Save outer fold model for external testing\n",
    "    model_path = MODELS_DIR / f\"xgb_nested_outer_{outer_idx + 1:02d}.pkl\"\n",
    "    joblib.dump(final_model, model_path)\n",
    "    print(f\"Saved outer fold model to: {model_path}\")\n",
    "\n",
    "    # ============================\n",
    "    # Evaluate on outer Test subjects\n",
    "    # ============================\n",
    "    fold_metrics = evaluate_metrics(y_test, y_test_pred, label_set)\n",
    "    print_metrics(fold_metrics, header=f\"OUTER Fold {outer_idx + 1} Test Metrics\")\n",
    "\n",
    "    all_test_y_true.append(y_test)\n",
    "    all_test_y_pred.append(y_test_pred)\n",
    "    outer_macro_f1_list.append(fold_metrics[\"macro_f1\"])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Global metrics across all outer folds (model as a whole)\n",
    "# ============================================================\n",
    "\n",
    "all_test_y_true = np.concatenate(all_test_y_true)\n",
    "all_test_y_pred = np.concatenate(all_test_y_pred)\n",
    "\n",
    "global_metrics = evaluate_metrics(all_test_y_true, all_test_y_pred, label_set)\n",
    "print_metrics(global_metrics, header=\"GLOBAL Test Metrics Across All OUTER Folds (XGBoost)\")\n",
    "\n",
    "print(\"\\nNested 10×10 N-LNSO evaluation with XGBoost completed.\")\n",
    "print(\"All outer-fold models are saved and ready for external testing.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5b) Summary of best inner-loop ROC AUC per outer fold + CSV\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary of inner-loop ROC AUC used to select best hyperparameters (XGBoost)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "auc_rows = []\n",
    "for i, (p, auc_val) in enumerate(zip(outer_best_params_list, outer_best_auc_list), start=1):\n",
    "    print(f\"OUTER Fold {i:02d}: best inner mean macro ROC AUC = {auc_val:.4f}\")\n",
    "    print(f\"  Selected params: {p}\")\n",
    "    row = {\n",
    "        \"outer_fold\": i,\n",
    "        \"best_inner_mean_macro_roc_auc\": auc_val,\n",
    "        \"n_estimators\": p[\"n_estimators\"],\n",
    "        \"max_depth\": p[\"max_depth\"],\n",
    "        \"learning_rate\": p[\"learning_rate\"],\n",
    "        \"subsample\": p[\"subsample\"],\n",
    "        \"colsample_bytree\": p[\"colsample_bytree\"],\n",
    "    }\n",
    "    auc_rows.append(row)\n",
    "\n",
    "inner_auc_df = pd.DataFrame(auc_rows)\n",
    "inner_auc_csv_path = MODELS_DIR / \"xgb_inner_auc_summary.csv\"\n",
    "inner_auc_df.to_csv(inner_auc_csv_path, index=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Inner-loop ROC AUC summary saved to: {inner_auc_csv_path}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Train a single FINAL deployment model on all subjects\n",
    "#    using the best hyperparameters discovered in nested CV\n",
    "# ============================================================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "combo_counts = defaultdict(int)\n",
    "combo_f1_sum = defaultdict(float)\n",
    "\n",
    "# Aggregate hyperparameter performance over outer folds\n",
    "for params, macro_f1 in zip(outer_best_params_list, outer_macro_f1_list):\n",
    "    # Convert dict to a hashable key (tuple of sorted items)\n",
    "    key = tuple(sorted(params.items()))\n",
    "    combo_counts[key] += 1\n",
    "    combo_f1_sum[key] += float(macro_f1)\n",
    "\n",
    "# Choose the hyperparameter combo:\n",
    "# 1) with the highest frequency across outer folds\n",
    "# 2) break ties by highest sum of macro-F1\n",
    "best_key = None\n",
    "best_count = -1\n",
    "best_f1_sum = -np.inf\n",
    "\n",
    "for key in combo_counts:\n",
    "    count = combo_counts[key]\n",
    "    f1_sum = combo_f1_sum[key]\n",
    "    if (count > best_count) or (count == best_count and f1_sum > best_f1_sum):\n",
    "        best_count = count\n",
    "        best_f1_sum = f1_sum\n",
    "        best_key = key\n",
    "\n",
    "final_params = dict(best_key)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Selected FINAL deployment hyperparameters (based on outer folds, XGBoost):\")\n",
    "print(final_params)\n",
    "print(f\"Selected combo frequency across outer folds: {best_count}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Undersampling on the full dataset (all subjects)\n",
    "X_full_bal, y_full_bal = undersample_multiclass(\n",
    "    X_all, y_all,\n",
    "    max_ratio=3.0,\n",
    "    random_state=RANDOM_STATE + 999\n",
    ")\n",
    "\n",
    "# Train final deployment XGBoost model on all balanced data\n",
    "final_deployment_model, _ = xgb_fit_predict(\n",
    "    X_full_bal, y_full_bal,\n",
    "    X_full_bal,   # dummy predictions, not used\n",
    "    final_params,\n",
    "    n_classes=n_classes\n",
    ")\n",
    "\n",
    "deployment_model_path = MODELS_DIR / \"xgb_final_deployment.pkl\"\n",
    "joblib.dump(final_deployment_model, deployment_model_path)\n",
    "\n",
    "print(\"\\nFinal deployment XGBoost model trained on all subjects and saved to:\")\n",
    "print(deployment_model_path)\n",
    "print(\"Use this model for real-time or external testing on new patients.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cacfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.utils import shuffle\n",
    "import joblib\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ============================================================\n",
    "# 1) Paths and basic settings (edit these to match your system)\n",
    "# ============================================================\n",
    "\n",
    "# Path to the fused dataset (CSV)\n",
    "DATA_PATH = Path(r\"C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\Data\\FUSED_ALL_FINAL_FROM_DATA_ALL.csv\")\n",
    "\n",
    "# Directory where all XGBoost models and CSV summaries will be saved\n",
    "MODELS_DIR = Path(r\"C:\\Users\\LENOVO\\Downloads\\Senior_Proj\\Final\\output\\XGBoost_Model\")\n",
    "\n",
    "# Column names for subject ID and label\n",
    "SUBJECT_COL = \"subject\"\n",
    "LABEL_COL   = \"label\"\n",
    "\n",
    "# Global random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Number of outer and inner folds for nested N-LNSO\n",
    "N_OUTER_FOLDS = 10\n",
    "N_INNER_FOLDS = 10\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Helper functions\n",
    "# ============================================================\n",
    "\n",
    "def make_subject_folds(subject_ids, n_folds=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Create subject-wise folds:\n",
    "    - Take unique subject IDs\n",
    "    - Shuffle them\n",
    "    - Split them into n_folds groups\n",
    "    Each fold contains a set of subjects (not windows).\n",
    "    \"\"\"\n",
    "    unique_subjects = np.array(sorted(np.unique(subject_ids)))\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    rng.shuffle(unique_subjects)\n",
    "    folds = np.array_split(unique_subjects, n_folds)\n",
    "    return folds\n",
    "\n",
    "\n",
    "def undersample_multiclass(X, y, max_ratio=3.0, random_state=42):\n",
    "    \"\"\"\n",
    "    Random undersampling for imbalanced multi-class data.\n",
    "    For each class c:\n",
    "        keep at most (max_ratio * min_class_count) samples.\n",
    "    This avoids extreme imbalance across classes.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    min_count = counts.min()\n",
    "    max_per_class = {c: int(min_count * max_ratio) for c in classes}\n",
    "\n",
    "    indices_to_keep = []\n",
    "\n",
    "    for c in classes:\n",
    "        class_indices = np.where(y == c)[0]\n",
    "        n_keep = min(len(class_indices), max_per_class[c])\n",
    "        chosen = rng.choice(class_indices, size=n_keep, replace=False)\n",
    "        indices_to_keep.append(chosen)\n",
    "\n",
    "    indices_to_keep = np.concatenate(indices_to_keep)\n",
    "    indices_to_keep = shuffle(indices_to_keep, random_state=random_state)\n",
    "\n",
    "    return X[indices_to_keep], y[indices_to_keep]\n",
    "\n",
    "\n",
    "def get_xgb_model(params, n_classes, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Build an XGBClassifier for multi-class classification\n",
    "    using the provided hyperparameters.\n",
    "\n",
    "    XGBoost >= 2.0:\n",
    "      - GPU:  tree_method=\"hist\", device=\"cuda\"\n",
    "      - CPU:  tree_method=\"hist\"\n",
    "    \"\"\"\n",
    "    base_kwargs = dict(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        subsample=params[\"subsample\"],\n",
    "        colsample_bytree=params[\"colsample_bytree\"],\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=n_classes,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    if use_gpu:\n",
    "        try:\n",
    "            # 🔥 GPU mode (الطريقة الجديدة)\n",
    "            model = XGBClassifier(\n",
    "                tree_method=\"hist\",\n",
    "                device=\"cuda\",\n",
    "                **base_kwargs,\n",
    "            )\n",
    "            print(\"[XGBoost] Using GPU (hist + device='cuda') ✅\")\n",
    "        except Exception as e:\n",
    "            print(\"[XGBoost] GPU not available, falling back to CPU ❌\")\n",
    "            print(\"Reason:\", e)\n",
    "            model = XGBClassifier(\n",
    "                tree_method=\"hist\",\n",
    "                **base_kwargs,\n",
    "            )\n",
    "    else:\n",
    "        # 🧠 CPU فقط\n",
    "        model = XGBClassifier(\n",
    "            tree_method=\"hist\",\n",
    "            **base_kwargs,\n",
    "        )\n",
    "        print(\"[XGBoost] Using CPU only (hist) 🧠\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def xgb_fit_predict_proba(X_train, y_train, X_val, params, n_classes):\n",
    "    \"\"\"\n",
    "    Train XGBoost on (X_train, y_train) and predict class probabilities on X_val.\n",
    "    Returns:\n",
    "        model       - trained XGBClassifier\n",
    "        y_val_proba - numpy array of shape (n_samples_val, n_classes)\n",
    "    \"\"\"\n",
    "    model = get_xgb_model(params, n_classes, use_gpu=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_proba = model.predict_proba(X_val)\n",
    "    return model, y_val_proba\n",
    "\n",
    "\n",
    "def xgb_fit_predict(X_train, y_train, X_test, params, n_classes):\n",
    "    \"\"\"\n",
    "    Train XGBoost on (X_train, y_train) and predict class labels on X_test.\n",
    "    Returns:\n",
    "        model       - trained XGBClassifier\n",
    "        y_test_pred - numpy array of predicted class labels\n",
    "    \"\"\"\n",
    "    model = get_xgb_model(params, n_classes, use_gpu=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    return model, y_test_pred\n",
    "\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred, label_set=None):\n",
    "    \"\"\"\n",
    "    Compute per-class and global evaluation metrics:\n",
    "    - per-class precision, recall, f1, support\n",
    "    - accuracy, balanced accuracy, micro-F1, macro-F1, weighted-F1\n",
    "    - confusion matrix\n",
    "    \"\"\"\n",
    "    if label_set is None:\n",
    "        label_set = np.unique(y_true)\n",
    "\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=label_set, zero_division=0\n",
    "    )\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    micro_f1 = f1_score(y_true, y_pred, average=\"micro\")\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=label_set)\n",
    "\n",
    "    metrics = {\n",
    "        \"labels\": label_set,\n",
    "        \"precision_per_class\": prec,\n",
    "        \"recall_per_class\": rec,\n",
    "        \"f1_per_class\": f1,\n",
    "        \"support_per_class\": support,\n",
    "        \"accuracy\": acc,\n",
    "        \"balanced_accuracy\": bal_acc,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"weighted_f1\": weighted_f1,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_metrics(metrics, header=\"\"):\n",
    "    \"\"\"\n",
    "    Pretty-print per-class and global metrics,\n",
    "    and show TP/FP/FN/TN per label from the confusion matrix.\n",
    "    \"\"\"\n",
    "    labels = metrics[\"labels\"]\n",
    "    prec = metrics[\"precision_per_class\"]\n",
    "    rec = metrics[\"recall_per_class\"]\n",
    "    f1 = metrics[\"f1_per_class\"]\n",
    "    support = metrics[\"support_per_class\"]\n",
    "    cm = metrics[\"confusion_matrix\"]\n",
    "\n",
    "    if header:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(header)\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    print(\"label\\tprecision\\trecall\\t\\tf1-score\\tsupport\")\n",
    "    for i, c in enumerate(labels):\n",
    "        print(f\"{c}\\t{prec[i]:.4f}\\t\\t{rec[i]:.4f}\\t\\t{f1[i]:.4f}\\t\\t{support[i]}\")\n",
    "\n",
    "    print(\"\\nGlobal metrics:\")\n",
    "    print(f\"Accuracy          : {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Balanced Accuracy : {metrics['balanced_accuracy']:.4f}\")\n",
    "    print(f\"Micro-F1          : {metrics['micro_f1']:.4f}\")\n",
    "    print(f\"Macro-F1          : {metrics['macro_f1']:.4f}\")\n",
    "    print(f\"Weighted-F1       : {metrics['weighted_f1']:.4f}\")\n",
    "\n",
    "    print(\"\\nConfusion matrix (rows = true, cols = predicted):\")\n",
    "    print(cm)\n",
    "\n",
    "    total = cm.sum()\n",
    "    print(\"\\nPer-class confusion details (TP, FP, FN, TN):\")\n",
    "    for idx, c in enumerate(labels):\n",
    "        TP = cm[idx, idx]\n",
    "        FP = cm[:, idx].sum() - TP\n",
    "        FN = cm[idx, :].sum() - TP\n",
    "        TN = total - (TP + FP + FN)\n",
    "        print(f\"Label {c}: TP={TP}, FP={FP}, FN={FN}, TN={TN}\")\n",
    "\n",
    "\n",
    "def compute_inner_roc_auc_for_params(\n",
    "    X, y, subjects, label_set, param_grid, n_inner_folds=10, max_ratio=3.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Inner loop for nested N-LNSO:\n",
    "    - Split train+val subjects into n_inner_folds (subject-wise).\n",
    "    - For each hyperparameter combination:\n",
    "        - Train on inner-train subjects (with undersampling)\n",
    "        - Validate on inner-val subjects\n",
    "        - Compute macro ROC AUC (multi-class 'ovr')\n",
    "    - Return:\n",
    "        best_params, best_auc\n",
    "    \"\"\"\n",
    "    inner_folds = make_subject_folds(\n",
    "        subjects, n_folds=n_inner_folds, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    combo_scores = []\n",
    "    n_classes = len(label_set)\n",
    "\n",
    "    print(\"\\n------------------------------------------------------\")\n",
    "    print(\"Inner loop ROC AUC hyperparameter tuning (XGBoost)\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "\n",
    "    for combo_idx, params in enumerate(param_grid):\n",
    "        fold_aucs = []\n",
    "\n",
    "        for inner_idx, inner_val_subjects in enumerate(inner_folds):\n",
    "            # Subject-wise split for inner validation\n",
    "            is_inner_val = np.isin(subjects, inner_val_subjects)\n",
    "            is_inner_train = ~is_inner_val\n",
    "\n",
    "            X_inner_train = X[is_inner_train]\n",
    "            y_inner_train = y[is_inner_train]\n",
    "            X_inner_val   = X[is_inner_val]\n",
    "            y_inner_val   = y[is_inner_val]\n",
    "\n",
    "            # Undersampling on inner training set (only)\n",
    "            X_inner_train_bal, y_inner_train_bal = undersample_multiclass(\n",
    "                X_inner_train,\n",
    "                y_inner_train,\n",
    "                max_ratio=max_ratio,\n",
    "                random_state=RANDOM_STATE + inner_idx\n",
    "            )\n",
    "\n",
    "            # Train XGBoost and get probabilities on validation set\n",
    "            _, y_inner_val_proba = xgb_fit_predict_proba(\n",
    "                X_inner_train_bal, y_inner_train_bal,\n",
    "                X_inner_val,\n",
    "                params,\n",
    "                n_classes=n_classes\n",
    "            )\n",
    "\n",
    "            # Compute macro ROC AUC if possible for this fold\n",
    "            try:\n",
    "                auc = roc_auc_score(\n",
    "                    y_inner_val,\n",
    "                    y_inner_val_proba,\n",
    "                    labels=label_set,\n",
    "                    multi_class=\"ovr\",\n",
    "                    average=\"macro\"\n",
    "                )\n",
    "                fold_aucs.append(auc)\n",
    "            except ValueError:\n",
    "                # If the validation fold has only one class, ROC AUC is undefined\n",
    "                # => skip this fold for AUC calculation\n",
    "                continue\n",
    "\n",
    "        # Mean ROC AUC across inner folds for this hyperparameter combination\n",
    "        if len(fold_aucs) == 0:\n",
    "            mean_auc = np.nan\n",
    "        else:\n",
    "            mean_auc = float(np.mean(fold_aucs))\n",
    "\n",
    "        combo_scores.append((params, mean_auc))\n",
    "        print(f\"Combo {combo_idx + 1}/{len(param_grid)}: \"\n",
    "              f\"{params} --> mean macro ROC AUC = {mean_auc:.4f}\")\n",
    "\n",
    "    # Filter out combinations where all inner-fold AUCs were NaN\n",
    "    combo_scores = [c for c in combo_scores if not np.isnan(c[1])]\n",
    "    if len(combo_scores) == 0:\n",
    "        raise RuntimeError(\"All inner ROC AUC scores are NaN. Check your data splits or labels.\")\n",
    "\n",
    "    # Select the hyperparameters with the highest mean ROC AUC\n",
    "    best_params, best_auc = max(combo_scores, key=lambda t: t[1])\n",
    "\n",
    "    print(\"\\nBest inner hyperparameters based on ROC AUC:\")\n",
    "    print(best_params)\n",
    "    print(f\"Best inner mean macro ROC AUC: {best_auc:.4f}\")\n",
    "\n",
    "    return best_params, best_auc\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Load data and define feature/meta columns\n",
    "# ============================================================\n",
    "\n",
    "print(\"Loading fused dataset...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "if SUBJECT_COL not in df.columns or LABEL_COL not in df.columns:\n",
    "    raise ValueError(\"Check SUBJECT_COL and LABEL_COL names. They are not found in the dataframe.\")\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df[LABEL_COL].value_counts())\n",
    "print(\"\\nLabel proportions (%):\")\n",
    "print(df[LABEL_COL].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Meta columns (not used as features)\n",
    "meta_cols = [\n",
    "    \"subject\", \"run\", \"window_idx\", \"label\", \"run_base\",\n",
    "    \"ecg_start_time_sec\", \"t_start\", \"t_end\",\n",
    "    \"win_idx\", \"Unnamed: 0\", \"timestamp_center\"\n",
    "]\n",
    "# Keep only those that actually exist in the dataframe\n",
    "meta_cols = [c for c in meta_cols if c in df.columns]\n",
    "\n",
    "print(\"\\nMeta columns:\")\n",
    "print(meta_cols)\n",
    "\n",
    "# ========= هنا التعديل حق ch1 / ch2 =========\n",
    "\n",
    "# Select only numeric columns as candidate features\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "# 1) استبعاد أعمدة الميتا من الأعمدة الرقمية\n",
    "all_feature_cols = [c for c in numeric_cols if c not in meta_cols]\n",
    "\n",
    "# 2) اختيار فقط الفيتشرز اللي تبدأ بـ ch1 أو ch2\n",
    "feature_cols = [\n",
    "    c for c in all_feature_cols\n",
    "    if c.startswith(\"ch1\") or c.startswith(\"ch2\")\n",
    "]\n",
    "\n",
    "print(f\"\\nNumber of feature columns (ch1*/ch2* only): {len(feature_cols)}\")\n",
    "print(\"Example feature columns:\", feature_cols[:10])\n",
    "\n",
    "# Build X, y, and subject arrays\n",
    "X_all = df[feature_cols].values\n",
    "y_all = df[LABEL_COL].values\n",
    "subjects_all = df[SUBJECT_COL].values\n",
    "\n",
    "label_set = np.unique(y_all)\n",
    "print(f\"Unique labels: {label_set}\")\n",
    "\n",
    "n_classes = len(label_set)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Nested 10x10 N-LNSO with ROC AUC inner tuning (XGBoost)\n",
    "# ============================================================\n",
    "\n",
    "# Hyperparameter grid for inner ROC AUC tuning.\n",
    "param_grid = []\n",
    "\n",
    "n_estimators_list      = [300, 600, 1000]\n",
    "max_depth_list         = [4, 6, 8]\n",
    "learning_rate_list     = [0.05, 0.1]\n",
    "subsample_list         = [0.8]\n",
    "colsample_bytree_list  = [0.8]\n",
    "\n",
    "for ne in n_estimators_list:\n",
    "    for md in max_depth_list:\n",
    "        for lr in learning_rate_list:\n",
    "            for ss in subsample_list:\n",
    "                for cs in colsample_bytree_list:\n",
    "                    param_grid.append({\n",
    "                        \"n_estimators\": ne,\n",
    "                        \"max_depth\": md,\n",
    "                        \"learning_rate\": lr,\n",
    "                        \"subsample\": ss,\n",
    "                        \"colsample_bytree\": cs,\n",
    "                    })\n",
    "\n",
    "print(f\"\\nTotal hyperparameter combinations in inner loop: {len(param_grid)}\")\n",
    "\n",
    "# Outer folds (N-LNSO outer loop at subject level)\n",
    "outer_folds = make_subject_folds(\n",
    "    subjects_all,\n",
    "    n_folds=N_OUTER_FOLDS,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "all_test_y_true = []\n",
    "all_test_y_pred = []\n",
    "\n",
    "# Store best hyperparameters and macro-F1 from each outer fold\n",
    "outer_best_params_list = []\n",
    "outer_macro_f1_list = []\n",
    "outer_best_auc_list = []\n",
    "\n",
    "for outer_idx, outer_test_subjects in enumerate(outer_folds):\n",
    "    print(\"\\n\" + \"#\" * 80)\n",
    "    print(f\"OUTER Fold {outer_idx + 1}/{N_OUTER_FOLDS}\")\n",
    "    print(\"#\" * 80)\n",
    "\n",
    "    # Subject-wise split into Test vs Train+Val for this outer fold\n",
    "    is_test = np.isin(subjects_all, outer_test_subjects)\n",
    "    is_trainval = ~is_test\n",
    "\n",
    "    X_trainval = X_all[is_trainval]\n",
    "    y_trainval = y_all[is_trainval]\n",
    "    subjects_trainval = subjects_all[is_trainval]\n",
    "\n",
    "    X_test = X_all[is_test]\n",
    "    y_test = y_all[is_test]\n",
    "    subjects_test = subjects_all[is_test]\n",
    "\n",
    "    print(f\"Train+Val subjects: {len(np.unique(subjects_trainval))}, \"\n",
    "          f\"Test subjects: {len(np.unique(subjects_test))}\")\n",
    "\n",
    "    # ============================\n",
    "    # Inner loop: ROC AUC tuning\n",
    "    # ============================\n",
    "    best_inner_params, best_inner_auc = compute_inner_roc_auc_for_params(\n",
    "        X_trainval, y_trainval, subjects_trainval,\n",
    "        label_set=label_set,\n",
    "        param_grid=param_grid,\n",
    "        n_inner_folds=N_INNER_FOLDS,\n",
    "        max_ratio=3.0\n",
    "    )\n",
    "\n",
    "    outer_best_params_list.append(best_inner_params)\n",
    "    outer_best_auc_list.append(best_inner_auc)\n",
    "\n",
    "    # ============================\n",
    "    # Train final model on all Train+Val with undersampling\n",
    "    # ============================\n",
    "    X_trainval_bal, y_trainval_bal = undersample_multiclass(\n",
    "        X_trainval, y_trainval,\n",
    "        max_ratio=3.0,\n",
    "        random_state=RANDOM_STATE + outer_idx\n",
    "    )\n",
    "\n",
    "    final_model, y_test_pred = xgb_fit_predict(\n",
    "        X_trainval_bal, y_trainval_bal,\n",
    "        X_test,\n",
    "        best_inner_params,\n",
    "        n_classes=n_classes\n",
    "    )\n",
    "\n",
    "    # Save outer fold model for external testing\n",
    "    model_path = MODELS_DIR / f\"xgb_nested_outer_{outer_idx + 1:02d}.pkl\"\n",
    "    joblib.dump(final_model, model_path)\n",
    "    print(f\"Saved outer fold model to: {model_path}\")\n",
    "\n",
    "    # ============================\n",
    "    # Evaluate on outer Test subjects\n",
    "    # ============================\n",
    "    fold_metrics = evaluate_metrics(y_test, y_test_pred, label_set)\n",
    "    print_metrics(fold_metrics, header=f\"OUTER Fold {outer_idx + 1} Test Metrics\")\n",
    "\n",
    "    all_test_y_true.append(y_test)\n",
    "    all_test_y_pred.append(y_test_pred)\n",
    "    outer_macro_f1_list.append(fold_metrics[\"macro_f1\"])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Global metrics across all outer folds (model as a whole)\n",
    "# ============================================================\n",
    "\n",
    "all_test_y_true = np.concatenate(all_test_y_true)\n",
    "all_test_y_pred = np.concatenate(all_test_y_pred)\n",
    "\n",
    "global_metrics = evaluate_metrics(all_test_y_true, all_test_y_pred, label_set)\n",
    "print_metrics(global_metrics, header=\"GLOBAL Test Metrics Across All OUTER Folds (XGBoost)\")\n",
    "\n",
    "print(\"\\nNested 10×10 N-LNSO evaluation with XGBoost completed.\")\n",
    "print(\"All outer-fold models are saved and ready for external testing.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5b) Summary of best inner-loop ROC AUC per outer fold + CSV\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Summary of inner-loop ROC AUC used to select best hyperparameters (XGBoost)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "auc_rows = []\n",
    "for i, (p, auc_val) in enumerate(zip(outer_best_params_list, outer_best_auc_list), start=1):\n",
    "    print(f\"OUTER Fold {i:02d}: best inner mean macro ROC AUC = {auc_val:.4f}\")\n",
    "    print(f\"  Selected params: {p}\")\n",
    "    row = {\n",
    "        \"outer_fold\": i,\n",
    "        \"best_inner_mean_macro_roc_auc\": auc_val,\n",
    "        \"n_estimators\": p[\"n_estimators\"],\n",
    "        \"max_depth\": p[\"max_depth\"],\n",
    "        \"learning_rate\": p[\"learning_rate\"],\n",
    "        \"subsample\": p[\"subsample\"],\n",
    "        \"colsample_bytree\": p[\"colsample_bytree\"],\n",
    "    }\n",
    "    auc_rows.append(row)\n",
    "\n",
    "inner_auc_df = pd.DataFrame(auc_rows)\n",
    "inner_auc_csv_path = MODELS_DIR / \"xgb_inner_auc_summary.csv\"\n",
    "inner_auc_df.to_csv(inner_auc_csv_path, index=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Inner-loop ROC AUC summary saved to: {inner_auc_csv_path}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Train a single FINAL deployment model on all subjects\n",
    "#    using the best hyperparameters discovered in nested CV\n",
    "# ============================================================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "combo_counts = defaultdict(int)\n",
    "combo_f1_sum = defaultdict(float)\n",
    "\n",
    "# Aggregate hyperparameter performance over outer folds\n",
    "for params, macro_f1 in zip(outer_best_params_list, outer_macro_f1_list):\n",
    "    # Convert dict to a hashable key (tuple of sorted items)\n",
    "    key = tuple(sorted(params.items()))\n",
    "    combo_counts[key] += 1\n",
    "    combo_f1_sum[key] += float(macro_f1)\n",
    "\n",
    "# Choose the hyperparameter combo:\n",
    "# 1) with the highest frequency across outer folds\n",
    "# 2) break ties by highest sum of macro-F1\n",
    "best_key = None\n",
    "best_count = -1\n",
    "best_f1_sum = -np.inf\n",
    "\n",
    "for key in combo_counts:\n",
    "    count = combo_counts[key]\n",
    "    f1_sum = combo_f1_sum[key]\n",
    "    if (count > best_count) or (count == best_count and f1_sum > best_f1_sum):\n",
    "        best_count = count\n",
    "        best_f1_sum = f1_sum\n",
    "        best_key = key\n",
    "\n",
    "final_params = dict(best_key)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Selected FINAL deployment hyperparameters (based on outer folds, XGBoost):\")\n",
    "print(final_params)\n",
    "print(f\"Selected combo frequency across outer folds: {best_count}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Undersampling on the full dataset (all subjects)\n",
    "X_full_bal, y_full_bal = undersample_multiclass(\n",
    "    X_all, y_all,\n",
    "    max_ratio=3.0,\n",
    "    random_state=RANDOM_STATE + 999\n",
    ")\n",
    "\n",
    "# Train final deployment XGBoost model on all balanced data\n",
    "final_deployment_model, _ = xgb_fit_predict(\n",
    "    X_full_bal, y_full_bal,\n",
    "    X_full_bal,   # dummy predictions, not used\n",
    "    final_params,\n",
    "    n_classes=n_classes\n",
    ")\n",
    "\n",
    "deployment_model_path = MODELS_DIR / \"xgb_final_deployment.pkl\"\n",
    "joblib.dump(final_deployment_model, deployment_model_path)\n",
    "\n",
    "print(\"\\nFinal deployment XGBoost model trained on all subjects and saved to:\")\n",
    "print(deployment_model_path)\n",
    "print(\"Use this model for real-time or external testing on new patients.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088bc70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
