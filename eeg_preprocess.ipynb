{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ae74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pywt\n",
    "\n",
    "mne.set_log_level(\"WARNING\")\n",
    "\n",
    "# =========================================\n",
    "# 0) Paths + constants\n",
    "# =========================================\n",
    "\n",
    "BASE_DIR = Path(r\"C:\\SeniorProject_Data\")\n",
    "\n",
    "RUNS_CSV = Path(r\"C:\\SeniorProject\\Good_Data\\seizure_runs_details.csv\")\n",
    "\n",
    "OUT_FEAT_CSV = Path(r\"C:\\SeniorProject\\Good_Data\\MOV_Good_Runs.csv\")\n",
    "\n",
    "WINDOW_SEC   = 2.0         \n",
    "PREICTAL_SEC = 15 * 60     \n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"RUNS_CSV exists:\", RUNS_CSV.exists())\n",
    "\n",
    "runs_table = pd.read_csv(RUNS_CSV)\n",
    "runs_table[\"subject\"] = runs_table[\"subject\"].astype(str).str.strip()   # Ù…Ø«Ù„ sub-001\n",
    "runs_table[\"session\"] = runs_table[\"session\"].astype(str).str.strip()   # Ù…Ø«Ù„ ses-01\n",
    "runs_table[\"run\"]     = pd.to_numeric(runs_table[\"run\"], errors=\"raise\").astype(int)\n",
    "\n",
    "print(\"Runs table shape:\", runs_table.shape)\n",
    "display(runs_table.head())\n",
    "\n",
    "\n",
    "\n",
    "def build_state_mask_from_runs(raw, subject, session, run, runs_df, preictal_sec=PREICTAL_SEC):\n",
    "    \n",
    "    sf = raw.info[\"sfreq\"]\n",
    "    n_samples = raw.n_times\n",
    "    mask = np.zeros(n_samples, dtype=np.int8)\n",
    "\n",
    "    # Ù†Ø®ØªØ§Ø± ØµÙÙˆÙ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø±ÙŠØ¶ / Ø§Ù„Ø³ÙŠØ´Ù† / Ø§Ù„Ø±Ù† Ù…Ù† CSV\n",
    "    sub_df = runs_df[\n",
    "        (runs_df[\"subject\"] == subject) &\n",
    "        (runs_df[\"session\"] == session) &\n",
    "        (runs_df[\"run\"] == int(run))\n",
    "    ].copy()\n",
    "\n",
    "    if sub_df.empty:\n",
    "        print(f\"â„¹ No seizures in CSV for {subject} | {session} | run-{run:02d} â†’ ÙƒÙ„ Ø§Ù„Ù…Ø§Ø³Ùƒ = 0\")\n",
    "        return mask\n",
    "\n",
    "    sub_df[\"onset\"]    = pd.to_numeric(sub_df[\"onset\"], errors=\"coerce\")\n",
    "    sub_df[\"duration\"] = pd.to_numeric(sub_df[\"duration\"], errors=\"coerce\")\n",
    "    sub_df = sub_df.dropna(subset=[\"onset\", \"duration\"])\n",
    "\n",
    "    if sub_df.empty:\n",
    "        print(f\"â„¹ Seizure rows for {subject} | {session} | run-{run:02d} have NaN onset/duration â†’ ÙƒÙ„ Ø§Ù„Ù…Ø§Ø³Ùƒ = 0\")\n",
    "        return mask\n",
    "\n",
    "    print(f\"âœ… Found {len(sub_df)} seizures in CSV for {subject} | {session} | run-{run:02d}\")\n",
    "    if \"eventType\" in sub_df.columns:\n",
    "        print(sub_df[[\"onset\", \"duration\", \"eventType\"]])\n",
    "    else:\n",
    "        print(sub_df[[\"onset\", \"duration\"]])\n",
    "\n",
    "    for _, row in sub_df.iterrows():\n",
    "        onset_sec = float(row[\"onset\"])\n",
    "        dur_sec   = float(row[\"duration\"])\n",
    "\n",
    "        ictal_start = int(onset_sec * sf)\n",
    "        ictal_end   = int((onset_sec + dur_sec) * sf)\n",
    "\n",
    "        ictal_start = max(0, min(ictal_start, n_samples))\n",
    "        ictal_end   = max(0, min(ictal_end,   n_samples))\n",
    "\n",
    "        pre_start = max(0, ictal_start - int(preictal_sec * sf))\n",
    "\n",
    "        # pre-ictal\n",
    "        mask[pre_start:ictal_start] = 1\n",
    "        # ictal\n",
    "        mask[ictal_start:ictal_end] = 2\n",
    "\n",
    "    n0 = int((mask == 0).sum())\n",
    "    n1 = int((mask == 1).sum())\n",
    "    n2 = int((mask == 2).sum())\n",
    "    print(f\"Samples per class: 0={n0} ({n0/sf:.1f}s), 1={n1} ({n1/sf:.1f}s), 2={n2/sf:.1f}s\")\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 2) ECG/EMG artefact helpers\n",
    "# =========================================\n",
    "def prepare_ref_for_regression(eeg_raw, ref_raw, ref_name=\"REF\"):\n",
    "    if ref_raw is None:\n",
    "        print(f\"[{ref_name}] No reference file.\")\n",
    "        return None\n",
    "\n",
    "    sf_eeg = eeg_raw.info[\"sfreq\"]\n",
    "    sf_ref = ref_raw.info[\"sfreq\"]\n",
    "\n",
    "    ref = ref_raw.copy()\n",
    "    if sf_ref != sf_eeg:\n",
    "        print(f\"[{ref_name}] Resampling reference from {sf_ref} Hz to {sf_eeg} Hz (ref only).\")\n",
    "        ref.resample(sfreq=sf_eeg, npad=\"auto\")\n",
    "\n",
    "    eeg_len = eeg_raw.n_times\n",
    "    ref_data = ref.get_data()\n",
    "    ref_len = ref_data.shape[1]\n",
    "\n",
    "    if ref_len > eeg_len:\n",
    "        ref_data = ref_data[:, :eeg_len]\n",
    "    elif ref_len < eeg_len:\n",
    "        pad = np.zeros((ref_data.shape[0], eeg_len - ref_len), dtype=ref_data.dtype)\n",
    "        ref_data = np.concatenate([ref_data, pad], axis=1)\n",
    "\n",
    "    if np.var(ref_data) < 1e-10:\n",
    "        print(f\"[{ref_name}] Reference almost flat â†’ skip.\")\n",
    "        return None\n",
    "\n",
    "    return ref_data\n",
    "\n",
    "\n",
    "def regression_artifact_removal(eeg_raw, ref_raw, ref_name=\"REF\"):\n",
    "    ref_data = prepare_ref_for_regression(eeg_raw, ref_raw, ref_name=ref_name)\n",
    "    if ref_data is None:\n",
    "        print(f\"[{ref_name}] Regression skipped.\")\n",
    "        return eeg_raw.copy()\n",
    "\n",
    "    Y = eeg_raw.get_data()\n",
    "    X_ref = ref_data\n",
    "\n",
    "    X = np.vstack([X_ref, np.ones((1, X_ref.shape[1]))]).T\n",
    "    Y_T = Y.T\n",
    "\n",
    "    beta, _, _, _ = np.linalg.lstsq(X, Y_T, rcond=None)\n",
    "    artefact = (X @ beta).T\n",
    "    cleaned  = Y - artefact\n",
    "\n",
    "    out = eeg_raw.copy()\n",
    "    out._data = cleaned\n",
    "    print(f\"[{ref_name}] Regression artefact removal done.\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def has_ecg_artefact(eeg_raw, ecg_raw, corr_thresh=0.3):\n",
    "    ref_data = prepare_ref_for_regression(eeg_raw, ecg_raw, ref_name=\"ECG\")\n",
    "    if ref_data is None:\n",
    "        return False\n",
    "\n",
    "    eeg_data = eeg_raw.get_data()\n",
    "    ref_ch   = ref_data[0]\n",
    "\n",
    "    corrs = []\n",
    "    for ch_idx in range(eeg_data.shape[0]):\n",
    "        sig = eeg_data[ch_idx]\n",
    "        c = np.corrcoef(sig, ref_ch)[0, 1]\n",
    "        if not np.isnan(c):\n",
    "            corrs.append(abs(c))\n",
    "\n",
    "    if not corrs:\n",
    "        return False\n",
    "\n",
    "    max_corr = max(corrs)\n",
    "    print(f\"[ECG] max |corr(EEG, ECG)| = {max_corr:.3f}\")\n",
    "    return max_corr >= corr_thresh\n",
    "\n",
    "\n",
    "def has_emg_artefact(eeg_raw, high_freq_band=(40.0, 100.0), ratio_thresh=0.3):\n",
    "    data = eeg_raw.get_data()\n",
    "    sf   = eeg_raw.info[\"sfreq\"]\n",
    "\n",
    "    hf = mne.filter.filter_data(\n",
    "        data, sf,\n",
    "        l_freq=high_freq_band[0],\n",
    "        h_freq=high_freq_band[1],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    hf_power    = np.mean(hf**2, axis=1)\n",
    "    total_power = np.mean(data**2, axis=1) + 1e-12\n",
    "    ratios = hf_power / total_power\n",
    "    median_ratio = float(np.median(ratios))\n",
    "\n",
    "    print(f\"[EMG] median HF(40â€“100Hz)/total power = {median_ratio:.3f}\")\n",
    "    return median_ratio >= ratio_thresh\n",
    "\n",
    "\n",
    "def wavelet_denoise_emg_raw(eeg_raw, wavelet=\"db4\", level=2, thr_scale=0.5):\n",
    "    data = eeg_raw.get_data()\n",
    "    denoised = np.zeros_like(data)\n",
    "\n",
    "    for ch in range(data.shape[0]):\n",
    "        sig = data[ch, :]\n",
    "        coeffs = pywt.wavedec(sig, wavelet, level=level)\n",
    "        sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "        thr = thr_scale * sigma * np.sqrt(2 * np.log(len(sig)))\n",
    "\n",
    "        new_coeffs = [coeffs[0]]\n",
    "        for d in coeffs[1:]:\n",
    "            new_d = pywt.threshold(d, thr, mode=\"soft\")\n",
    "            new_coeffs.append(new_d)\n",
    "\n",
    "        recon = pywt.waverec(new_coeffs, wavelet)\n",
    "        if len(recon) > len(sig):\n",
    "            recon = recon[:len(sig)]\n",
    "        elif len(recon) < len(sig):\n",
    "            pad = np.zeros(len(sig) - len(recon))\n",
    "            recon = np.concatenate([recon, pad])\n",
    "        denoised[ch, :] = recon\n",
    "\n",
    "    out = eeg_raw.copy()\n",
    "    out._data = denoised\n",
    "    print(\"[EMG] Wavelet denoising done.\")\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def window_and_label(eeg_raw, state_mask, win_sec=WINDOW_SEC):\n",
    "\n",
    "    sf = eeg_raw.info[\"sfreq\"]\n",
    "    data = eeg_raw.get_data()\n",
    "    n_ch, n_samples = data.shape\n",
    "\n",
    "    win_samples = int(win_sec * sf)\n",
    "    if n_samples < win_samples:\n",
    "        print(\"âš  Run too short.\")\n",
    "        return None, None\n",
    "\n",
    "    mask = np.asarray(state_mask, dtype=np.int8)\n",
    "    if mask.size < n_samples:\n",
    "        pad = np.zeros(n_samples - mask.size, dtype=np.int8)\n",
    "        mask = np.concatenate([mask, pad])\n",
    "    elif mask.size > n_samples:\n",
    "        mask = mask[:n_samples]\n",
    "\n",
    "    starts = np.arange(0, n_samples - win_samples + 1, win_samples)\n",
    "\n",
    "    X_list, y_list = [], []\n",
    "    for s in starts:\n",
    "        e = s + win_samples\n",
    "        seg = data[:, s:e]\n",
    "        seg_mask = mask[s:e]\n",
    "\n",
    "        if seg_mask.size == 0:\n",
    "            lab = 0\n",
    "        else:\n",
    "            if (seg_mask == 2).any():\n",
    "                lab = 2\n",
    "            elif (seg_mask == 1).any():\n",
    "                lab = 1\n",
    "            else:\n",
    "                lab = 0\n",
    "\n",
    "        X_list.append(seg)\n",
    "        y_list.append(lab)\n",
    "\n",
    "    if not X_list:\n",
    "        return None, None\n",
    "\n",
    "    X = np.stack(X_list, axis=0)          # (n_windows, n_channels, n_samples)\n",
    "    y = np.array(y_list, dtype=np.int8)   # (n_windows,)\n",
    "\n",
    "    print(f\"[window_and_label] X shape = {X.shape}\")\n",
    "    print(f\"[window_and_label] label counts = {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 4) Feature helpers PER-CHANNEL\n",
    "# =========================================\n",
    "def compute_bandpowers_and_relative(x, sf):\n",
    "    \"\"\"\n",
    "    - Absolute bandpowers:\n",
    "        Delta (0.5â€“4), Theta (4â€“8), Alpha (8â€“12),\n",
    "        Beta (12â€“30), Gamma (30â€“45)\n",
    "    - Relative bandpowers = abs / sum(abs)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    n = x.size\n",
    "\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0 / sf)\n",
    "    fft_vals = np.fft.rfft(x)\n",
    "    psd = (np.abs(fft_vals) ** 2) / n  # power spectrum\n",
    "\n",
    "    def band_power(fmin, fmax):\n",
    "        mask = (freqs >= fmin) & (freqs < fmax)\n",
    "        if not np.any(mask):\n",
    "            return 0.0\n",
    "        return psd[mask].sum()\n",
    "\n",
    "    bp_delta = band_power(0.5, 4.0)\n",
    "    bp_theta = band_power(4.0, 8.0)\n",
    "    bp_alpha = band_power(8.0, 12.0)\n",
    "    bp_beta  = band_power(12.0, 30.0)\n",
    "    bp_gamma = band_power(30.0, 45.0)\n",
    "\n",
    "    total_bp = bp_delta + bp_theta + bp_alpha + bp_beta + bp_gamma + 1e-12\n",
    "\n",
    "    return {\n",
    "        \"Delta Bandpower\": bp_delta,\n",
    "        \"Theta Bandpower\": bp_theta,\n",
    "        \"Alpha Bandpower\": bp_alpha,\n",
    "        \"Beta Bandpower\":  bp_beta,\n",
    "        \"Gamma Bandpower\": bp_gamma,\n",
    "\n",
    "        \"Relative Delta Bandpower\": bp_delta / total_bp,\n",
    "        \"Relative Theta Bandpower\": bp_theta / total_bp,\n",
    "        \"Relative Alpha Bandpower\": bp_alpha / total_bp,\n",
    "        \"Relative Beta Bandpower\":  bp_beta  / total_bp,\n",
    "        \"Relative Gamma Bandpower\": bp_gamma / total_bp,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_time_features(x):\n",
    "    \"\"\"\n",
    "    - Interquartile Range\n",
    "    - Median Absolute Deviation\n",
    "    - Mean\n",
    "    - Median\n",
    "    - Variance\n",
    "    - Entropy\n",
    "    - Standard Deviation\n",
    "    - Skewness\n",
    "    - Kurtosis\n",
    "    - Line Length\n",
    "    - Hjorth Parameters: activity, mobility, complexity\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    mean = np.mean(x)\n",
    "    median = np.median(x)\n",
    "    var = np.var(x)\n",
    "    std = np.sqrt(var + 1e-12)\n",
    "\n",
    "    q1 = np.percentile(x, 25)\n",
    "    q3 = np.percentile(x, 75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    mad = np.median(np.abs(x - median))\n",
    "\n",
    "    # Entropy\n",
    "    if np.allclose(x, x[0]):\n",
    "        entropy = 0.0\n",
    "    else:\n",
    "        hist, _ = np.histogram(x, bins=50, density=True)\n",
    "        p = hist + 1e-12\n",
    "        p = p / p.sum()\n",
    "        entropy = -np.sum(p * np.log2(p))\n",
    "\n",
    "    centered = x - mean\n",
    "    m3 = np.mean(centered**3)\n",
    "    m4 = np.mean(centered**4)\n",
    "    skew = m3 / (std**3 + 1e-12)\n",
    "    kurt = m4 / (std**4 + 1e-12)\n",
    "\n",
    "    line_len = np.sum(np.abs(np.diff(x)))\n",
    "\n",
    "    activity = var\n",
    "    dx = np.diff(x)\n",
    "    var_dx = np.var(dx)\n",
    "    mobility = np.sqrt(var_dx / (var + 1e-12))\n",
    "\n",
    "    ddx = np.diff(dx)\n",
    "    var_ddx = np.var(ddx) if ddx.size > 0 else 0.0\n",
    "    mobility_dx = np.sqrt(var_ddx / (var_dx + 1e-12)) if var_dx > 0 else 0.0\n",
    "    complexity = mobility_dx / (mobility + 1e-12)\n",
    "\n",
    "    return {\n",
    "        \"Interquartile Range\": iqr,\n",
    "        \"Median Absolute Deviation\": mad,\n",
    "        \"Mean\": mean,\n",
    "        \"Median\": median,\n",
    "        \"Variance\": var,\n",
    "        \"Entropy\": entropy,\n",
    "        \"Standard Deviation\": std,\n",
    "        \"Skewness\": skew,\n",
    "        \"Kurtosis\": kurt,\n",
    "        \"Line Length\": line_len,\n",
    "        \"Hjorth Activity\": activity,\n",
    "        \"Hjorth Mobility\": mobility,\n",
    "        \"Hjorth Complexity\": complexity,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_features_for_window(seg, sf):\n",
    "\n",
    "    n_ch, _ = seg.shape\n",
    "    feat_dict = {}\n",
    "\n",
    "    for ch in range(n_ch):\n",
    "        x = seg[ch, :]\n",
    "\n",
    "        bp_dict = compute_bandpowers_and_relative(x, sf)\n",
    "        td_dict = compute_time_features(x)\n",
    "\n",
    "        prefix = f\"ch{ch+1}_\"\n",
    "\n",
    "        for k, v in {**bp_dict, **td_dict}.items():\n",
    "            feat_dict[prefix + k] = v\n",
    "\n",
    "    return feat_dict\n",
    "\n",
    "\n",
    "\n",
    "def process_one_run(subject, session, run, runs_df):\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\"Processing {subject} | {session} | run-{run:02d}\")\n",
    "    print(\"====================================\")\n",
    "\n",
    "    run_base = f\"{subject}_{session}_task-szMonitoring_run-{run:02d}\"\n",
    "\n",
    "    eeg_path = BASE_DIR / subject / session / \"eeg\" / f\"{run_base}_eeg.edf\"\n",
    "    ecg_path = BASE_DIR / subject / session / \"ecg\" / f\"{run_base}_ecg.edf\"\n",
    "    emg_path = BASE_DIR / subject / session / \"emg\" / f\"{run_base}_emg.edf\"\n",
    "\n",
    "    print(\"EEG path:\", eeg_path, \"| exists:\", eeg_path.exists())\n",
    "    print(\"ECG path:\", ecg_path, \"| exists:\", ecg_path.exists())\n",
    "    print(\"EMG path:\", emg_path, \"| exists:\", emg_path.exists())\n",
    "\n",
    "    if not eeg_path.exists():\n",
    "        print(f\"âŒ EEG file not found â†’ SKIP this run.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        eeg_raw = mne.io.read_raw_edf(eeg_path, preload=True, verbose=\"ERROR\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading EEG: {e}\")\n",
    "        return None\n",
    "\n",
    "    ecg_raw = mne.io.read_raw_edf(ecg_path, preload=True, verbose=\"ERROR\") if ecg_path.exists() else None\n",
    "    emg_raw = mne.io.read_raw_edf(emg_path, preload=True, verbose=\"ERROR\") if emg_path.exists() else None\n",
    "\n",
    "    print(\"EEG sfreq:\", eeg_raw.info[\"sfreq\"], \"| n_channels:\", len(eeg_raw.ch_names))\n",
    "\n",
    "    # 1) Notch 50 Hz\n",
    "    eeg_notch = eeg_raw.copy()\n",
    "    eeg_notch.notch_filter(freqs=[50.0], verbose=False)\n",
    "\n",
    "    # 2) Band-pass 0.5â€“45 Hz\n",
    "    eeg_bp = eeg_notch.copy()\n",
    "    eeg_bp.filter(l_freq=0.5, h_freq=45.0, verbose=False)\n",
    "\n",
    "    # 3) state mask Ù…Ù† CSV\n",
    "    state_mask = build_state_mask_from_runs(\n",
    "        eeg_bp, subject=subject, session=session, run=run, runs_df=runs_df, preictal_sec=PREICTAL_SEC\n",
    "    )\n",
    "\n",
    "    # 4) ECG regression\n",
    "    if ecg_raw is not None and has_ecg_artefact(eeg_bp, ecg_raw):\n",
    "        eeg_ecg = regression_artifact_removal(eeg_bp, ecg_raw, ref_name=\"ECG\")\n",
    "    else:\n",
    "        print(\"[ECG] No strong ECG artefact â†’ skipping\")\n",
    "        eeg_ecg = eeg_bp.copy()\n",
    "\n",
    "    # 5) EMG wavelet denoise\n",
    "    if has_emg_artefact(eeg_ecg):\n",
    "        eeg_clean = wavelet_denoise_emg_raw(eeg_ecg, wavelet=\"db4\", level=2, thr_scale=0.5)\n",
    "    else:\n",
    "        print(\"[EMG] No strong EMG artefact â†’ skipping\")\n",
    "        eeg_clean = eeg_ecg.copy()\n",
    "\n",
    "    # 6) Windowing\n",
    "    X, y = window_and_label(eeg_clean, state_mask, win_sec=WINDOW_SEC)\n",
    "    if X is None or y is None:\n",
    "        print(\"âš  No windows for this run.\")\n",
    "        return None\n",
    "\n",
    "    n_normal   = int(np.sum(y == 0))\n",
    "    n_preictal = int(np.sum(y == 1))\n",
    "    n_ictal    = int(np.sum(y == 2))\n",
    "\n",
    "    print(\"\\n[Window Counts]\")\n",
    "    print(f\"\\U0001F7E6  Normal: {n_normal} windows\")\n",
    "    print(f\"\\U0001F7E7  Pre-ictal: {n_preictal} windows\")\n",
    "    print(f\"\\U0001F7E5  Ictal: {n_ictal} windows\")\n",
    "    print(f\"\\nâž¡ Finished run with Total windows: {len(y)}\\n\")\n",
    "    # =============================================\n",
    "\n",
    "    sf = float(eeg_clean.info[\"sfreq\"])\n",
    "    n_windows = X.shape[0]\n",
    "    n_ch = X.shape[1]\n",
    "    print(f\"Windows: {n_windows}, Channels: {n_ch}\")\n",
    "\n",
    "    rows = []\n",
    "    for w in range(n_windows):\n",
    "        seg = X[w, :, :]  # (n_ch, n_samples)\n",
    "        feat_dict = compute_features_for_window(seg, sf)\n",
    "\n",
    "        row = {\n",
    "            \"subject\": subject,\n",
    "            \"run\": int(run),\n",
    "            \"window_idx\": int(w),\n",
    "            \"label\": int(y[w]),\n",
    "        }\n",
    "        row.update(feat_dict)\n",
    "        rows.append(row)\n",
    "\n",
    "    df_run = pd.DataFrame(rows)\n",
    "    print(\"Run features shape:\", df_run.shape)\n",
    "    return df_run\n",
    "\n",
    "\n",
    "\n",
    "runs_table[\"sub_id\"] = runs_table[\"subject\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "\n",
    "runs_unique = runs_table[[\"subject\", \"session\", \"run\", \"sub_id\"]].drop_duplicates()\n",
    "\n",
    "print(\"ðŸ”¢ Total unique runs in CSV:\", len(runs_unique))\n",
    "\n",
    "batch1 = runs_unique.drop(columns=[\"sub_id\"]).head(200).copy()\n",
    "\n",
    "print(\"âœ… Batch 1 unique runs (first 200):\", len(batch1))\n",
    "display(batch1.head())\n",
    "first = True\n",
    "\n",
    "for idx, row in batch1.iterrows():\n",
    "    subject = str(row[\"subject\"]).strip()\n",
    "    session = str(row[\"session\"]).strip()\n",
    "    run     = int(row[\"run\"])\n",
    "\n",
    "    print(f\"\\nâž¡ Running {subject} | {session} | run-{run:02d}\")\n",
    "    df_run = process_one_run(subject, session, run, runs_df=runs_table)\n",
    "\n",
    "    if df_run is not None and not df_run.empty:\n",
    "        if first:\n",
    "            df_run.to_csv(OUT_FEAT_CSV, index=False, encoding=\"utf-8-sig\", mode=\"w\")\n",
    "            first = False\n",
    "        else:\n",
    "            df_run.to_csv(OUT_FEAT_CSV, index=False, encoding=\"utf-8-sig\", mode=\"a\", header=False)\n",
    "\n",
    "print(\"\\nðŸŽ‰ DONE! Saved Batch 1 per-window EEG features to:\")\n",
    "print(OUT_FEAT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8875de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import pywt\n",
    "\n",
    "mne.set_log_level(\"WARNING\")\n",
    "\n",
    "# =========================================\n",
    "# 0) Paths + constants\n",
    "# =========================================\n",
    "\n",
    "BASE_DIR = Path(r\"C:\\SeniorProject_Data\")\n",
    "\n",
    "RUNS_CSV = Path(r\"C:\\SeniorProject\\Good_Data\\seizure_runs_details.csv\")\n",
    "\n",
    "OUT_FEAT_CSV = Path(r\"C:\\SeniorProject\\Good_Data\\MOV_Good_Runs_Batch201-395.csv\")\n",
    "\n",
    "WINDOW_SEC   = 2.0          \n",
    "PREICTAL_SEC = 15 * 60    \n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"RUNS_CSV exists:\", RUNS_CSV.exists())\n",
    "\n",
    "runs_table = pd.read_csv(RUNS_CSV)\n",
    "runs_table[\"subject\"] = runs_table[\"subject\"].astype(str).str.strip()   # Ù…Ø«Ù„ sub-001\n",
    "runs_table[\"session\"] = runs_table[\"session\"].astype(str).str.strip()   # Ù…Ø«Ù„ ses-01\n",
    "runs_table[\"run\"]     = pd.to_numeric(runs_table[\"run\"], errors=\"raise\").astype(int)\n",
    "\n",
    "print(\"Runs table shape:\", runs_table.shape)\n",
    "display(runs_table.head())\n",
    "\n",
    "\n",
    "\n",
    "def build_state_mask_from_runs(raw, subject, session, run, runs_df, preictal_sec=PREICTAL_SEC):\n",
    "    sf = raw.info[\"sfreq\"]\n",
    "    n_samples = raw.n_times\n",
    "    mask = np.zeros(n_samples, dtype=np.int8)\n",
    "\n",
    "    sub_df = runs_df[\n",
    "        (runs_df[\"subject\"] == subject) &\n",
    "        (runs_df[\"session\"] == session) &\n",
    "        (runs_df[\"run\"] == int(run))\n",
    "    ].copy()\n",
    "\n",
    "    if sub_df.empty:\n",
    "        return mask\n",
    "\n",
    "    sub_df[\"onset\"]    = pd.to_numeric(sub_df[\"onset\"], errors=\"coerce\")\n",
    "    sub_df[\"duration\"] = pd.to_numeric(sub_df[\"duration\"], errors=\"coerce\")\n",
    "    sub_df = sub_df.dropna(subset=[\"onset\", \"duration\"])\n",
    "\n",
    "    if sub_df.empty:\n",
    "        return mask\n",
    "\n",
    "    for _, row in sub_df.iterrows():\n",
    "        onset_sec = float(row[\"onset\"])\n",
    "        dur_sec   = float(row[\"duration\"])\n",
    "\n",
    "        ictal_start = int(onset_sec * sf)\n",
    "        ictal_end   = int((onset_sec + dur_sec) * sf)\n",
    "\n",
    "        ictal_start = max(0, min(ictal_start, n_samples))\n",
    "        ictal_end   = max(0, min(ictal_end,   n_samples))\n",
    "\n",
    "        pre_start = max(0, ictal_start - int(preictal_sec * sf))\n",
    "\n",
    "        mask[pre_start:ictal_start] = 1\n",
    "        mask[ictal_start:ictal_end] = 2\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 2) ECG/EMG artefact helpers\n",
    "# =========================================\n",
    "def prepare_ref_for_regression(eeg_raw, ref_raw, ref_name=\"REF\"):\n",
    "    if ref_raw is None:\n",
    "        print(f\"[{ref_name}] No reference file.\")\n",
    "        return None\n",
    "\n",
    "    sf_eeg = eeg_raw.info[\"sfreq\"]\n",
    "    sf_ref = ref_raw.info[\"sfreq\"]\n",
    "\n",
    "    ref = ref_raw.copy()\n",
    "    if sf_ref != sf_eeg:\n",
    "        print(f\"[{ref_name}] Resampling reference from {sf_ref} Hz to {sf_eeg} Hz (ref only).\")\n",
    "        ref.resample(sfreq=sf_eeg, npad=\"auto\")\n",
    "\n",
    "    eeg_len = eeg_raw.n_times\n",
    "    ref_data = ref.get_data()\n",
    "    ref_len = ref_data.shape[1]\n",
    "\n",
    "    if ref_len > eeg_len:\n",
    "        ref_data = ref_data[:, :eeg_len]\n",
    "    elif ref_len < eeg_len:\n",
    "        pad = np.zeros((ref_data.shape[0], eeg_len - ref_len), dtype=ref_data.dtype)\n",
    "        ref_data = np.concatenate([ref_data, pad], axis=1)\n",
    "\n",
    "    if np.var(ref_data) < 1e-10:\n",
    "        print(f\"[{ref_name}] Reference almost flat â†’ skip.\")\n",
    "        return None\n",
    "\n",
    "    return ref_data\n",
    "\n",
    "\n",
    "def regression_artifact_removal(eeg_raw, ref_raw, ref_name=\"REF\"):\n",
    "    ref_data = prepare_ref_for_regression(eeg_raw, ref_raw, ref_name=ref_name)\n",
    "    if ref_data is None:\n",
    "        print(f\"[{ref_name}] Regression skipped.\")\n",
    "        return eeg_raw.copy()\n",
    "\n",
    "    Y = eeg_raw.get_data()\n",
    "    X_ref = ref_data\n",
    "\n",
    "    X = np.vstack([X_ref, np.ones((1, X_ref.shape[1]))]).T\n",
    "    Y_T = Y.T\n",
    "\n",
    "    beta, _, _, _ = np.linalg.lstsq(X, Y_T, rcond=None)\n",
    "    artefact = (X @ beta).T\n",
    "    cleaned  = Y - artefact\n",
    "\n",
    "    out = eeg_raw.copy()\n",
    "    out._data = cleaned\n",
    "    print(f\"[{ref_name}] Regression artefact removal done.\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def has_ecg_artefact(eeg_raw, ecg_raw, corr_thresh=0.3):\n",
    "    ref_data = prepare_ref_for_regression(eeg_raw, ecg_raw, ref_name=\"ECG\")\n",
    "    if ref_data is None:\n",
    "        return False\n",
    "\n",
    "    eeg_data = eeg_raw.get_data()\n",
    "    ref_ch   = ref_data[0]\n",
    "\n",
    "    corrs = []\n",
    "    for ch_idx in range(eeg_data.shape[0]):\n",
    "        sig = eeg_data[ch_idx]\n",
    "        c = np.corrcoef(sig, ref_ch)[0, 1]\n",
    "        if not np.isnan(c):\n",
    "            corrs.append(abs(c))\n",
    "\n",
    "    if not corrs:\n",
    "        return False\n",
    "\n",
    "    max_corr = max(corrs)\n",
    "    print(f\"[ECG] max |corr(EEG, ECG)| = {max_corr:.3f}\")\n",
    "    return max_corr >= corr_thresh\n",
    "\n",
    "\n",
    "def has_emg_artefact(eeg_raw, high_freq_band=(40.0, 100.0), ratio_thresh=0.3):\n",
    "    data = eeg_raw.get_data()\n",
    "    sf   = eeg_raw.info[\"sfreq\"]\n",
    "\n",
    "    hf = mne.filter.filter_data(\n",
    "        data, sf,\n",
    "        l_freq=high_freq_band[0],\n",
    "        h_freq=high_freq_band[1],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    hf_power    = np.mean(hf**2, axis=1)\n",
    "    total_power = np.mean(data**2, axis=1) + 1e-12\n",
    "    ratios = hf_power / total_power\n",
    "    median_ratio = float(np.median(ratios))\n",
    "\n",
    "    print(f\"[EMG] median HF(40â€“100Hz)/total power = {median_ratio:.3f}\")\n",
    "    return median_ratio >= ratio_thresh\n",
    "\n",
    "\n",
    "def wavelet_denoise_emg_raw(eeg_raw, wavelet=\"db4\", level=2, thr_scale=0.5):\n",
    "    data = eeg_raw.get_data()\n",
    "    denoised = np.zeros_like(data)\n",
    "\n",
    "    for ch in range(data.shape[0]):\n",
    "        sig = data[ch, :]\n",
    "        coeffs = pywt.wavedec(sig, wavelet, level=level)\n",
    "        sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "        thr = thr_scale * sigma * np.sqrt(2 * np.log(len(sig)))\n",
    "\n",
    "        new_coeffs = [coeffs[0]]\n",
    "        for d in coeffs[1:]:\n",
    "            new_d = pywt.threshold(d, thr, mode=\"soft\")\n",
    "            new_coeffs.append(new_d)\n",
    "\n",
    "        recon = pywt.waverec(new_coeffs, wavelet)\n",
    "        if len(recon) > len(sig):\n",
    "            recon = recon[:len(sig)]\n",
    "        elif len(recon) < len(sig):\n",
    "            pad = np.zeros(len(sig) - len(recon))\n",
    "            recon = np.concatenate([recon, pad])\n",
    "        denoised[ch, :] = recon\n",
    "\n",
    "    out = eeg_raw.copy()\n",
    "    out._data = denoised\n",
    "    print(\"[EMG] Wavelet denoising done.\")\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def window_and_label(eeg_raw, state_mask, win_sec=WINDOW_SEC):\n",
    " \n",
    "    sf = eeg_raw.info[\"sfreq\"]\n",
    "    data = eeg_raw.get_data()\n",
    "    n_ch, n_samples = data.shape\n",
    "\n",
    "    win_samples = int(win_sec * sf)\n",
    "    if n_samples < win_samples:\n",
    "        print(\"âš  Run too short.\")\n",
    "        return None, None\n",
    "\n",
    "    mask = np.asarray(state_mask, dtype=np.int8)\n",
    "    if mask.size < n_samples:\n",
    "        pad = np.zeros(n_samples - mask.size, dtype=np.int8)\n",
    "        mask = np.concatenate([mask, pad])\n",
    "    elif mask.size > n_samples:\n",
    "        mask = mask[:n_samples]\n",
    "\n",
    "    starts = np.arange(0, n_samples - win_samples + 1, win_samples)\n",
    "\n",
    "    X_list, y_list = [], []\n",
    "    for s in starts:\n",
    "        e = s + win_samples\n",
    "        seg = data[:, s:e]\n",
    "        seg_mask = mask[s:e]\n",
    "\n",
    "        if seg_mask.size == 0:\n",
    "            lab = 0\n",
    "        else:\n",
    "            if (seg_mask == 2).any():\n",
    "                lab = 2\n",
    "            elif (seg_mask == 1).any():\n",
    "                lab = 1\n",
    "            else:\n",
    "                lab = 0\n",
    "\n",
    "        X_list.append(seg)\n",
    "        y_list.append(lab)\n",
    "\n",
    "    if not X_list:\n",
    "        return None, None\n",
    "\n",
    "    X = np.stack(X_list, axis=0)          # (n_windows, n_channels, n_samples)\n",
    "    y = np.array(y_list, dtype=np.int8)   # (n_windows,)\n",
    "\n",
    "    print(f\"[window_and_label] X shape = {X.shape}\")\n",
    "    print(f\"[window_and_label] label counts = {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 4) Feature helpers PER-CHANNEL\n",
    "# =========================================\n",
    "def compute_bandpowers_and_relative(x, sf):\n",
    "    \"\"\"\n",
    "    - Absolute bandpowers:\n",
    "        Delta (0.5â€“4), Theta (4â€“8), Alpha (8â€“12),\n",
    "        Beta (12â€“30), Gamma (30â€“45)\n",
    "    - Relative bandpowers = abs / sum(abs)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    n = x.size\n",
    "\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0 / sf)\n",
    "    fft_vals = np.fft.rfft(x)\n",
    "    psd = (np.abs(fft_vals) ** 2) / n  # power spectrum\n",
    "\n",
    "    def band_power(fmin, fmax):\n",
    "        mask = (freqs >= fmin) & (freqs < fmax)\n",
    "        if not np.any(mask):\n",
    "            return 0.0\n",
    "        return psd[mask].sum()\n",
    "\n",
    "    bp_delta = band_power(0.5, 4.0)\n",
    "    bp_theta = band_power(4.0, 8.0)\n",
    "    bp_alpha = band_power(8.0, 12.0)\n",
    "    bp_beta  = band_power(12.0, 30.0)\n",
    "    bp_gamma = band_power(30.0, 45.0)\n",
    "\n",
    "    total_bp = bp_delta + bp_theta + bp_alpha + bp_beta + bp_gamma + 1e-12\n",
    "\n",
    "    return {\n",
    "        \"Delta Bandpower\": bp_delta,\n",
    "        \"Theta Bandpower\": bp_theta,\n",
    "        \"Alpha Bandpower\": bp_alpha,\n",
    "        \"Beta Bandpower\":  bp_beta,\n",
    "        \"Gamma Bandpower\": bp_gamma,\n",
    "\n",
    "        \"Relative Delta Bandpower\": bp_delta / total_bp,\n",
    "        \"Relative Theta Bandpower\": bp_theta / total_bp,\n",
    "        \"Relative Alpha Bandpower\": bp_alpha / total_bp,\n",
    "        \"Relative Beta Bandpower\":  bp_beta  / total_bp,\n",
    "        \"Relative Gamma Bandpower\": bp_gamma / total_bp,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_time_features(x):\n",
    "    \"\"\"\n",
    "    - Interquartile Range\n",
    "    - Median Absolute Deviation\n",
    "    - Mean\n",
    "    - Median\n",
    "    - Variance\n",
    "    - Entropy\n",
    "    - Standard Deviation\n",
    "    - Skewness\n",
    "    - Kurtosis\n",
    "    - Line Length\n",
    "    - Hjorth Parameters: activity, mobility, complexity\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "\n",
    "    mean = np.mean(x)\n",
    "    median = np.median(x)\n",
    "    var = np.var(x)\n",
    "    std = np.sqrt(var + 1e-12)\n",
    "\n",
    "    q1 = np.percentile(x, 25)\n",
    "    q3 = np.percentile(x, 75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    mad = np.median(np.abs(x - median))\n",
    "\n",
    "    # Entropy\n",
    "    if np.allclose(x, x[0]):\n",
    "        entropy = 0.0\n",
    "    else:\n",
    "        hist, _ = np.histogram(x, bins=50, density=True)\n",
    "        p = hist + 1e-12\n",
    "        p = p / p.sum()\n",
    "        entropy = -np.sum(p * np.log2(p))\n",
    "\n",
    "    centered = x - mean\n",
    "    m3 = np.mean(centered**3)\n",
    "    m4 = np.mean(centered**4)\n",
    "    skew = m3 / (std**3 + 1e-12)\n",
    "    kurt = m4 / (std**4 + 1e-12)\n",
    "\n",
    "    line_len = np.sum(np.abs(np.diff(x)))\n",
    "\n",
    "    activity = var\n",
    "    dx = np.diff(x)\n",
    "    var_dx = np.var(dx)\n",
    "    mobility = np.sqrt(var_dx / (var + 1e-12))\n",
    "\n",
    "    ddx = np.diff(dx)\n",
    "    var_ddx = np.var(ddx) if ddx.size > 0 else 0.0\n",
    "    mobility_dx = np.sqrt(var_ddx / (var_dx + 1e-12)) if var_dx > 0 else 0.0\n",
    "    complexity = mobility_dx / (mobility + 1e-12)\n",
    "\n",
    "    return {\n",
    "        \"Interquartile Range\": iqr,\n",
    "        \"Median Absolute Deviation\": mad,\n",
    "        \"Mean\": mean,\n",
    "        \"Median\": median,\n",
    "        \"Variance\": var,\n",
    "        \"Entropy\": entropy,\n",
    "        \"Standard Deviation\": std,\n",
    "        \"Skewness\": skew,\n",
    "        \"Kurtosis\": kurt,\n",
    "        \"Line Length\": line_len,\n",
    "        \"Hjorth Activity\": activity,\n",
    "        \"Hjorth Mobility\": mobility,\n",
    "        \"Hjorth Complexity\": complexity,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_features_for_window(seg, sf):\n",
    "\n",
    "    n_ch, _ = seg.shape\n",
    "    feat_dict = {}\n",
    "\n",
    "    for ch in range(n_ch):\n",
    "        x = seg[ch, :]\n",
    "\n",
    "        bp_dict = compute_bandpowers_and_relative(x, sf)\n",
    "        td_dict = compute_time_features(x)\n",
    "\n",
    "        prefix = f\"ch{ch+1}_\"\n",
    "\n",
    "        for k, v in {**bp_dict, **td_dict}.items():\n",
    "            feat_dict[prefix + k] = v\n",
    "\n",
    "    return feat_dict\n",
    "\n",
    "\n",
    "def process_one_run(subject, session, run, runs_df):\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\"Processing {subject} | {session} | run-{run:02d}\")\n",
    "    print(\"====================================\")\n",
    "\n",
    "    run_base = f\"{subject}_{session}_task-szMonitoring_run-{run:02d}\"\n",
    "\n",
    "    eeg_path = BASE_DIR / subject / session / \"eeg\" / f\"{run_base}_eeg.edf\"\n",
    "    ecg_path = BASE_DIR / subject / session / \"ecg\" / f\"{run_base}_ecg.edf\"\n",
    "    emg_path = BASE_DIR / subject / session / \"emg\" / f\"{run_base}_emg.edf\"\n",
    "\n",
    "    if not eeg_path.exists():\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        eeg_raw = mne.io.read_raw_edf(eeg_path, preload=True, verbose=False)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    ecg_raw = mne.io.read_raw_edf(ecg_path, preload=True, verbose=False) if ecg_path.exists() else None\n",
    "    emg_raw = mne.io.read_raw_edf(emg_path, preload=True, verbose=False) if emg_path.exists() else None\n",
    "\n",
    "    # Notch + Bandpass without printing\n",
    "    eeg_bp = eeg_raw.copy()\n",
    "    eeg_bp.notch_filter(freqs=[50.0], verbose=False)\n",
    "    eeg_bp.filter(l_freq=0.5, h_freq=45.0, verbose=False)\n",
    "\n",
    "    # state mask ONLY (no prints)\n",
    "    state_mask = build_state_mask_from_runs(\n",
    "        eeg_bp, subject=subject, session=session, run=run, runs_df=runs_df, preictal_sec=PREICTAL_SEC\n",
    "    )\n",
    "\n",
    "    # ECG regression without prints\n",
    "    if ecg_raw is not None and has_ecg_artefact(eeg_bp, ecg_raw):\n",
    "        eeg_ecg = regression_artifact_removal(eeg_bp, ecg_raw, ref_name=\"ECG\")\n",
    "    else:\n",
    "        eeg_ecg = eeg_bp.copy()\n",
    "\n",
    "    # EMG wavelet denoise without prints\n",
    "    if has_emg_artefact(eeg_ecg):\n",
    "        eeg_clean = wavelet_denoise_emg_raw(eeg_ecg)\n",
    "    else:\n",
    "        eeg_clean = eeg_ecg.copy()\n",
    "\n",
    "    # Windowing\n",
    "    X, y = window_and_label(eeg_clean, state_mask, win_sec=WINDOW_SEC)\n",
    "    if X is None or y is None:\n",
    "        return None\n",
    "\n",
    "    # ======= ONLY the output you want =======\n",
    "    n_normal   = int(np.sum(y == 0))\n",
    "    n_preictal = int(np.sum(y == 1))\n",
    "    n_ictal    = int(np.sum(y == 2))\n",
    "\n",
    "    print(f\"ðŸŸ¦  Normal: {n_normal} windows\")\n",
    "    print(f\"ðŸŸ§  Pre-ictal: {n_preictal} windows\")\n",
    "    print(f\"ðŸŸ¥  Ictal: {n_ictal} windows\")\n",
    "    print(f\"\\nâž¡ Finished run with Total windows: {len(y)}\\n\")\n",
    "    # ========================================\n",
    "\n",
    "    # Feature extraction (no prints)\n",
    "    sf = float(eeg_clean.info[\"sfreq\"])\n",
    "    rows = []\n",
    "    for w in range(X.shape[0]):\n",
    "        seg = X[w, :, :]\n",
    "        feat_dict = compute_features_for_window(seg, sf)\n",
    "        row = {\"subject\": subject, \"run\": int(run), \"window_idx\": int(w), \"label\": int(y[w])}\n",
    "        row.update(feat_dict)\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "runs_table[\"sub_id\"] = runs_table[\"subject\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "\n",
    "runs_unique = runs_table[[\"subject\", \"session\", \"run\", \"sub_id\"]].drop_duplicates()\n",
    "\n",
    "print(\"ðŸ”¢ Total unique runs in CSV:\", len(runs_unique))\n",
    "\n",
    "batch1 = runs_unique.drop(columns=[\"sub_id\"]).iloc[200:395].copy()\n",
    "\n",
    "print(\"âœ… Batch 1 unique runs (first 200):\", len(batch1))\n",
    "display(batch1.head())\n",
    "\n",
    "first = True\n",
    "\n",
    "for idx, row in batch1.iterrows():\n",
    "    subject = str(row[\"subject\"]).strip()\n",
    "    session = str(row[\"session\"]).strip()\n",
    "    run     = int(row[\"run\"])\n",
    "\n",
    "    print(f\"\\nâž¡ Running {subject} | {session} | run-{run:02d}\")\n",
    "    df_run = process_one_run(subject, session, run, runs_df=runs_table)\n",
    "\n",
    "    if df_run is not None and not df_run.empty:\n",
    "        if first:\n",
    "            df_run.to_csv(OUT_FEAT_CSV, index=False, encoding=\"utf-8-sig\", mode=\"w\")\n",
    "            first = False\n",
    "        else:\n",
    "            df_run.to_csv(OUT_FEAT_CSV, index=False, encoding=\"utf-8-sig\", mode=\"a\", header=False)\n",
    "\n",
    "print(\"\\nðŸŽ‰ DONE! Saved Batch 1 per-window EEG features to:\")\n",
    "print(OUT_FEAT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d60892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 shape: (3593729, 50)\n",
      "Batch 2 shape: (1809830, 50)\n",
      "After concat shape: (5403559, 50)\n",
      "Duplicates removed: 0\n",
      "Shape after drop_duplicates: (5403559, 50)\n",
      "\n",
      "ðŸ“Š Number of unique runs in final file: 392\n",
      "First few runs:\n",
      "       subject  run\n",
      "0      sub-001    5\n",
      "31255  sub-001    7\n",
      "46014  sub-001    8\n",
      "71753  sub-002    1\n",
      "77443  sub-002    2\n",
      "\n",
      "âœ… Saved merged file to:\n",
      "C:\\Users\\LENOVO\\Desktop\\sen_proj\\eeg_MERGED.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "batch1 = r\"C:\\Users\\LENOVO\\Desktop\\sen_proj\\MOV_Good_Runs_Batch1-200.csv\"  \n",
    "batch2 = r\"C:\\Users\\LENOVO\\Desktop\\sen_proj\\MOV_Good_Runs_Batch201-395.csv\"  \n",
    "\n",
    "OUT = r\"C:\\Users\\LENOVO\\Desktop\\sen_proj\\eeg_MERGED.csv\" \n",
    "\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(batch1)\n",
    "df2 = pd.read_csv(batch2)\n",
    "\n",
    "print(\"Batch 1 shape:\", df1.shape)\n",
    "print(\"Batch 2 shape:\", df2.shape)\n",
    "\n",
    "\n",
    "\n",
    "df_all = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "print(\"After concat shape:\", df_all.shape)\n",
    "\n",
    "\n",
    "\n",
    "key_cols = [\"subject\", \"run\", \"window_idx\"]\n",
    "if \"session\" in df_all.columns:\n",
    "    key_cols = [\"subject\", \"session\", \"run\", \"window_idx\"]\n",
    "\n",
    "before_drop = df_all.shape[0]\n",
    "df_all = df_all.drop_duplicates(subset=key_cols, keep=\"first\")\n",
    "after_drop = df_all.shape[0]\n",
    "\n",
    "print(f\"Duplicates removed: {before_drop - after_drop}\")\n",
    "print(\"Shape after drop_duplicates:\", df_all.shape)\n",
    "\n",
    "\n",
    "df_all = df_all.sort_values(by=key_cols).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "run_key = [\"subject\", \"run\"]\n",
    "if \"session\" in df_all.columns:\n",
    "    run_key = [\"subject\", \"session\", \"run\"]\n",
    "\n",
    "unique_runs = df_all[run_key].drop_duplicates()\n",
    "n_runs = unique_runs.shape[0]\n",
    "\n",
    "print(f\"\\nðŸ“Š Number of unique runs in final file: {n_runs}\")\n",
    "print(\"First few runs:\")\n",
    "print(unique_runs.head())\n",
    "\n",
    "\n",
    "df_all.to_csv(OUT, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"\\nâœ… Saved merged file to:\")\n",
    "print(OUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
